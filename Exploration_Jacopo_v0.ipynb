{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration Notebook v0 - Jacopo\n",
    "\n",
    "To avoid cluttering the main notebook, I'm going to do some exploration here, it might get very messy as a whole but it should be easy to follow.\n",
    "\n",
    "This will probably be the first (zero) version of several notebooks. The version names should help with keeping track and I will name them -Jacopo to avoid confusion with the main notebook.\n",
    "\n",
    "## Folder Structure\n",
    "- `./`: Notebooks, Readme, gitignore and Data are in the root folder\n",
    "- `data/ `: all data in this folder, will be ignored by git but it will eventually include quite a lot, subfolders like `out/` for results, `data-ssd/` for YouNiverse dataset symlinked to an ssd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>categories</th>\n",
       "      <th>channel_id</th>\n",
       "      <th>dislike_count</th>\n",
       "      <th>display_id</th>\n",
       "      <th>duration</th>\n",
       "      <th>like_count</th>\n",
       "      <th>upload_date</th>\n",
       "      <th>view_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Film &amp; Animation</td>\n",
       "      <td>UCzWrhkg9eK5I8Bm3HfV-unA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>SBqSc91Hn9g</td>\n",
       "      <td>1159</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2016-09-28</td>\n",
       "      <td>1057.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Film &amp; Animation</td>\n",
       "      <td>UCzWrhkg9eK5I8Bm3HfV-unA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>UuugEl86ESY</td>\n",
       "      <td>2681</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2016-09-28</td>\n",
       "      <td>12894.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Film &amp; Animation</td>\n",
       "      <td>UCzWrhkg9eK5I8Bm3HfV-unA</td>\n",
       "      <td>779.0</td>\n",
       "      <td>oB4c-yvnbjs</td>\n",
       "      <td>1394</td>\n",
       "      <td>1607.0</td>\n",
       "      <td>2016-09-28</td>\n",
       "      <td>1800602.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Film &amp; Animation</td>\n",
       "      <td>UCzWrhkg9eK5I8Bm3HfV-unA</td>\n",
       "      <td>24.0</td>\n",
       "      <td>ZaV-gTCMV8E</td>\n",
       "      <td>5064</td>\n",
       "      <td>227.0</td>\n",
       "      <td>2016-09-28</td>\n",
       "      <td>57640.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Film &amp; Animation</td>\n",
       "      <td>UCzWrhkg9eK5I8Bm3HfV-unA</td>\n",
       "      <td>13.0</td>\n",
       "      <td>cGvL7AvMfM0</td>\n",
       "      <td>3554</td>\n",
       "      <td>105.0</td>\n",
       "      <td>2016-09-28</td>\n",
       "      <td>86368.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         categories                channel_id  dislike_count   display_id  \\\n",
       "0  Film & Animation  UCzWrhkg9eK5I8Bm3HfV-unA            1.0  SBqSc91Hn9g   \n",
       "1  Film & Animation  UCzWrhkg9eK5I8Bm3HfV-unA            1.0  UuugEl86ESY   \n",
       "2  Film & Animation  UCzWrhkg9eK5I8Bm3HfV-unA          779.0  oB4c-yvnbjs   \n",
       "3  Film & Animation  UCzWrhkg9eK5I8Bm3HfV-unA           24.0  ZaV-gTCMV8E   \n",
       "4  Film & Animation  UCzWrhkg9eK5I8Bm3HfV-unA           13.0  cGvL7AvMfM0   \n",
       "\n",
       "   duration  like_count upload_date  view_count  \n",
       "0      1159         8.0  2016-09-28      1057.0  \n",
       "1      2681        23.0  2016-09-28     12894.0  \n",
       "2      1394      1607.0  2016-09-28   1800602.0  \n",
       "3      5064       227.0  2016-09-28     57640.0  \n",
       "4      3554       105.0  2016-09-28     86368.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = \"data/data-ssd/full/\" \n",
    "\n",
    "#first of all let's create a 100k randomized sample for the bigger datasets so we can work with them nicely\n",
    "import random\n",
    "skip_rows = lambda i: i>0 and random.random() < 0.8\n",
    "#df_metadata = pd.read_json(data_path + \"yt_metadata_en.jsonl.gz\", lines=True, compression=\"gzip\", encoding=\"utf-8\", nrows=100000)\n",
    "df_metadata = pd.read_feather(path= data_path + \"yt_metadata_helper.feather\", use_threads=True)\n",
    "df_metadata.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 72924794 entries, 0 to 72924793\n",
      "Data columns (total 8 columns):\n",
      " #   Column         Dtype         \n",
      "---  ------         -----         \n",
      " 0   categories     object        \n",
      " 1   channel_id     object        \n",
      " 2   dislike_count  float64       \n",
      " 3   display_id     object        \n",
      " 4   duration       int64         \n",
      " 5   like_count     float64       \n",
      " 6   upload_date    datetime64[ns]\n",
      " 7   view_count     float64       \n",
      "dtypes: datetime64[ns](1), float64(3), int64(1), object(3)\n",
      "memory usage: 4.3+ GB\n"
     ]
    }
   ],
   "source": [
    "df_metadata.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 72924794 entries, 0 to 72924793\n",
      "Data columns (total 8 columns):\n",
      " #   Column         Dtype         \n",
      "---  ------         -----         \n",
      " 0   categories     object        \n",
      " 1   channel_id     object        \n",
      " 2   dislike_count  int16         \n",
      " 3   display_id     object        \n",
      " 4   duration       int16         \n",
      " 5   like_count     int16         \n",
      " 6   upload_date    datetime64[ns]\n",
      " 7   view_count     int32         \n",
      "dtypes: datetime64[ns](1), int16(3), int32(1), object(3)\n",
      "memory usage: 2.9+ GB\n"
     ]
    }
   ],
   "source": [
    "df_metadata['dislike_count'] = df_metadata['dislike_count'].notna().astype('int16')\n",
    "df_metadata['like_count'] = df_metadata['like_count'].notna().astype('int16')\n",
    "df_metadata['view_count'] = df_metadata['view_count'].notna().astype('int32')\n",
    "df_metadata['duration'] = df_metadata['duration'].notna().astype('int16')\n",
    "df_metadata.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save pickle\n",
    "import pickle\n",
    "with open(data_path + \"yt_metadata_helper.pkl\", \"wb\") as f:\n",
    "    pickle.dump(df_metadata, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>categories</th>\n",
       "      <th>channel_id</th>\n",
       "      <th>dislike_count</th>\n",
       "      <th>display_id</th>\n",
       "      <th>duration</th>\n",
       "      <th>like_count</th>\n",
       "      <th>upload_date</th>\n",
       "      <th>view_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>UCzWrhkg9eK5I8Bm3HfV-unA</td>\n",
       "      <td>1</td>\n",
       "      <td>SBqSc91Hn9g</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-09-28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>UCzWrhkg9eK5I8Bm3HfV-unA</td>\n",
       "      <td>1</td>\n",
       "      <td>UuugEl86ESY</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-09-28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>UCzWrhkg9eK5I8Bm3HfV-unA</td>\n",
       "      <td>1</td>\n",
       "      <td>oB4c-yvnbjs</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-09-28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>UCzWrhkg9eK5I8Bm3HfV-unA</td>\n",
       "      <td>1</td>\n",
       "      <td>ZaV-gTCMV8E</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-09-28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>UCzWrhkg9eK5I8Bm3HfV-unA</td>\n",
       "      <td>1</td>\n",
       "      <td>cGvL7AvMfM0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-09-28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   categories                channel_id  dislike_count   display_id  duration  \\\n",
       "0           5  UCzWrhkg9eK5I8Bm3HfV-unA              1  SBqSc91Hn9g         1   \n",
       "1           5  UCzWrhkg9eK5I8Bm3HfV-unA              1  UuugEl86ESY         1   \n",
       "2           5  UCzWrhkg9eK5I8Bm3HfV-unA              1  oB4c-yvnbjs         1   \n",
       "3           5  UCzWrhkg9eK5I8Bm3HfV-unA              1  ZaV-gTCMV8E         1   \n",
       "4           5  UCzWrhkg9eK5I8Bm3HfV-unA              1  cGvL7AvMfM0         1   \n",
       "\n",
       "   like_count upload_date  view_count  \n",
       "0           1  2016-09-28           1  \n",
       "1           1  2016-09-28           1  \n",
       "2           1  2016-09-28           1  \n",
       "3           1  2016-09-28           1  \n",
       "4           1  2016-09-28           1  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "df_metadata['categories'] = le.fit_transform(df_metadata['categories'])\n",
    "df_metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6     13720303\n",
      "4     12276397\n",
      "10     8881022\n",
      "9      8305003\n",
      "12     6910666\n",
      "16     4354412\n",
      "7      3968127\n",
      "3      3795564\n",
      "14     2403004\n",
      "5      2359736\n",
      "1      2256967\n",
      "2      1172503\n",
      "17     1096565\n",
      "11      777449\n",
      "13      645508\n",
      "0         1522\n",
      "15          41\n",
      "8            5\n",
      "Name: categories, dtype: int64\n",
      "['' 'Autos & Vehicles' 'Comedy' 'Education' 'Entertainment'\n",
      " 'Film & Animation' 'Gaming' 'Howto & Style' 'Movies' 'Music'\n",
      " 'News & Politics' 'Nonprofits & Activism' 'People & Blogs'\n",
      " 'Pets & Animals' 'Science & Technology' 'Shows' 'Sports'\n",
      " 'Travel & Events']\n"
     ]
    }
   ],
   "source": [
    "print(df_metadata['categories'].value_counts())\n",
    "print(le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 72924794 entries, 0 to 72924793\n",
      "Data columns (total 8 columns):\n",
      " #   Column         Dtype         \n",
      "---  ------         -----         \n",
      " 0   categories     int8          \n",
      " 1   channel_id     object        \n",
      " 2   dislike_count  int16         \n",
      " 3   display_id     object        \n",
      " 4   duration       int16         \n",
      " 5   like_count     int16         \n",
      " 6   upload_date    datetime64[ns]\n",
      " 7   view_count     int32         \n",
      "dtypes: datetime64[ns](1), int16(3), int32(1), int8(1), object(2)\n",
      "memory usage: 2.4+ GB\n"
     ]
    }
   ],
   "source": [
    "df_metadata['categories'] = df_metadata['categories'].astype('int8')\n",
    "df_metadata.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save pickle\n",
    "import pickle\n",
    "with open(data_path + \"yt_metadata_helper.pkl\", \"wb\") as f:\n",
    "    pickle.dump(df_metadata, f)\n",
    "\n",
    "# save categories\n",
    "with open(data_path + \"categories.pkl\", \"wb\") as f:\n",
    "    pickle.dump(le.classes_, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>categories</th>\n",
       "      <th>channel_id</th>\n",
       "      <th>dislike_count</th>\n",
       "      <th>display_id</th>\n",
       "      <th>duration</th>\n",
       "      <th>like_count</th>\n",
       "      <th>upload_date</th>\n",
       "      <th>view_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>UCzWrhkg9eK5I8Bm3HfV-unA</td>\n",
       "      <td>1</td>\n",
       "      <td>SBqSc91Hn9g</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-09-28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>UCzWrhkg9eK5I8Bm3HfV-unA</td>\n",
       "      <td>1</td>\n",
       "      <td>UuugEl86ESY</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-09-28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>UCzWrhkg9eK5I8Bm3HfV-unA</td>\n",
       "      <td>1</td>\n",
       "      <td>oB4c-yvnbjs</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-09-28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>UCzWrhkg9eK5I8Bm3HfV-unA</td>\n",
       "      <td>1</td>\n",
       "      <td>ZaV-gTCMV8E</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-09-28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>UCzWrhkg9eK5I8Bm3HfV-unA</td>\n",
       "      <td>1</td>\n",
       "      <td>cGvL7AvMfM0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-09-28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   categories                channel_id  dislike_count   display_id  duration  \\\n",
       "0           5  UCzWrhkg9eK5I8Bm3HfV-unA              1  SBqSc91Hn9g         1   \n",
       "1           5  UCzWrhkg9eK5I8Bm3HfV-unA              1  UuugEl86ESY         1   \n",
       "2           5  UCzWrhkg9eK5I8Bm3HfV-unA              1  oB4c-yvnbjs         1   \n",
       "3           5  UCzWrhkg9eK5I8Bm3HfV-unA              1  ZaV-gTCMV8E         1   \n",
       "4           5  UCzWrhkg9eK5I8Bm3HfV-unA              1  cGvL7AvMfM0         1   \n",
       "\n",
       "   like_count upload_date  view_count  \n",
       "0           1  2016-09-28           1  \n",
       "1           1  2016-09-28           1  \n",
       "2           1  2016-09-28           1  \n",
       "3           1  2016-09-28           1  \n",
       "4           1  2016-09-28           1  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2018    15275859\n",
       "2019    12723124\n",
       "2017    12486407\n",
       "2016     9352771\n",
       "2015     6808073\n",
       "2014     5179935\n",
       "2013     4018279\n",
       "2012     2926436\n",
       "2011     1874984\n",
       "2010     1085424\n",
       "2009      694586\n",
       "2008      338040\n",
       "2007      137250\n",
       "2006       23294\n",
       "2005         332\n",
       "Name: upload_date, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_metadata['upload_date'].dt.year.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>categories</th>\n",
       "      <th>channel_id</th>\n",
       "      <th>crawl_date</th>\n",
       "      <th>description</th>\n",
       "      <th>dislike_count</th>\n",
       "      <th>display_id</th>\n",
       "      <th>duration</th>\n",
       "      <th>like_count</th>\n",
       "      <th>tags</th>\n",
       "      <th>title</th>\n",
       "      <th>upload_date</th>\n",
       "      <th>view_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Film &amp; Animation</td>\n",
       "      <td>UCzWrhkg9eK5I8Bm3HfV-unA</td>\n",
       "      <td>2019-10-31 20:19:26.270363</td>\n",
       "      <td>Lego City Police Lego Firetruck Cartoons about...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>SBqSc91Hn9g</td>\n",
       "      <td>1159</td>\n",
       "      <td>8.0</td>\n",
       "      <td>lego city,lego police,lego city police,lego ci...</td>\n",
       "      <td>Lego City Police Lego Firetruck Cartoons about...</td>\n",
       "      <td>2016-09-28</td>\n",
       "      <td>1057.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Film &amp; Animation</td>\n",
       "      <td>UCzWrhkg9eK5I8Bm3HfV-unA</td>\n",
       "      <td>2019-10-31 20:19:26.914516</td>\n",
       "      <td>Lego Marvel SuperHeroes Lego Hulk Smash Iron-M...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>UuugEl86ESY</td>\n",
       "      <td>2681</td>\n",
       "      <td>23.0</td>\n",
       "      <td>Lego superheroes,lego hulk,hulk smash,lego mar...</td>\n",
       "      <td>Lego Marvel SuperHeroes Lego Hulk Smash Iron-M...</td>\n",
       "      <td>2016-09-28</td>\n",
       "      <td>12894.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Film &amp; Animation</td>\n",
       "      <td>UCzWrhkg9eK5I8Bm3HfV-unA</td>\n",
       "      <td>2019-10-31 20:19:26.531203</td>\n",
       "      <td>Lego City Police Lego Fireman Cartoons about L...</td>\n",
       "      <td>779.0</td>\n",
       "      <td>oB4c-yvnbjs</td>\n",
       "      <td>1394</td>\n",
       "      <td>1607.0</td>\n",
       "      <td>lego city,lego police,lego city police,lego fi...</td>\n",
       "      <td>Lego City Police Lego Fireman Cartoons about L...</td>\n",
       "      <td>2016-09-28</td>\n",
       "      <td>1800602.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Film &amp; Animation</td>\n",
       "      <td>UCzWrhkg9eK5I8Bm3HfV-unA</td>\n",
       "      <td>2019-10-31 20:19:28.335329</td>\n",
       "      <td>Lego Harry Potter Complete Lego New Movie for ...</td>\n",
       "      <td>24.0</td>\n",
       "      <td>ZaV-gTCMV8E</td>\n",
       "      <td>5064</td>\n",
       "      <td>227.0</td>\n",
       "      <td>Lego harry potter,new harry potter,harry potte...</td>\n",
       "      <td>Lego Harry Potter Complete Lego New Movie for ...</td>\n",
       "      <td>2016-09-28</td>\n",
       "      <td>57640.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Film &amp; Animation</td>\n",
       "      <td>UCzWrhkg9eK5I8Bm3HfV-unA</td>\n",
       "      <td>2019-10-31 20:19:30.328487</td>\n",
       "      <td>Lego City Police LONG VIDEO for kids Lego Fire...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>cGvL7AvMfM0</td>\n",
       "      <td>3554</td>\n",
       "      <td>105.0</td>\n",
       "      <td>lego city,lego police,lego city police,lego fi...</td>\n",
       "      <td>Lego City Police 1 HOUR LONG VIDEO for kids Le...</td>\n",
       "      <td>2016-09-28</td>\n",
       "      <td>86368.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         categories                channel_id                  crawl_date  \\\n",
       "0  Film & Animation  UCzWrhkg9eK5I8Bm3HfV-unA  2019-10-31 20:19:26.270363   \n",
       "1  Film & Animation  UCzWrhkg9eK5I8Bm3HfV-unA  2019-10-31 20:19:26.914516   \n",
       "2  Film & Animation  UCzWrhkg9eK5I8Bm3HfV-unA  2019-10-31 20:19:26.531203   \n",
       "3  Film & Animation  UCzWrhkg9eK5I8Bm3HfV-unA  2019-10-31 20:19:28.335329   \n",
       "4  Film & Animation  UCzWrhkg9eK5I8Bm3HfV-unA  2019-10-31 20:19:30.328487   \n",
       "\n",
       "                                         description  dislike_count  \\\n",
       "0  Lego City Police Lego Firetruck Cartoons about...            1.0   \n",
       "1  Lego Marvel SuperHeroes Lego Hulk Smash Iron-M...            1.0   \n",
       "2  Lego City Police Lego Fireman Cartoons about L...          779.0   \n",
       "3  Lego Harry Potter Complete Lego New Movie for ...           24.0   \n",
       "4  Lego City Police LONG VIDEO for kids Lego Fire...           13.0   \n",
       "\n",
       "    display_id  duration  like_count  \\\n",
       "0  SBqSc91Hn9g      1159         8.0   \n",
       "1  UuugEl86ESY      2681        23.0   \n",
       "2  oB4c-yvnbjs      1394      1607.0   \n",
       "3  ZaV-gTCMV8E      5064       227.0   \n",
       "4  cGvL7AvMfM0      3554       105.0   \n",
       "\n",
       "                                                tags  \\\n",
       "0  lego city,lego police,lego city police,lego ci...   \n",
       "1  Lego superheroes,lego hulk,hulk smash,lego mar...   \n",
       "2  lego city,lego police,lego city police,lego fi...   \n",
       "3  Lego harry potter,new harry potter,harry potte...   \n",
       "4  lego city,lego police,lego city police,lego fi...   \n",
       "\n",
       "                                               title upload_date  view_count  \n",
       "0  Lego City Police Lego Firetruck Cartoons about...  2016-09-28      1057.0  \n",
       "1  Lego Marvel SuperHeroes Lego Hulk Smash Iron-M...  2016-09-28     12894.0  \n",
       "2  Lego City Police Lego Fireman Cartoons about L...  2016-09-28   1800602.0  \n",
       "3  Lego Harry Potter Complete Lego New Movie for ...  2016-09-28     57640.0  \n",
       "4  Lego City Police 1 HOUR LONG VIDEO for kids Le...  2016-09-28     86368.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = \"data/data-ssd/full/\" \n",
    "# let's import the tags from the full dataset in order to encode them\n",
    "df_tags = pd.read_json(data_path + \"yt_metadata_en.jsonl.gz\", lines=True, compression=\"gzip\", encoding=\"utf-8\", \n",
    "dtype={'video_id': 'str', 'tags': 'str'}, nrows=1000000, convert_dates=['upload_date'])\n",
    "df_tags.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000000 entries, 0 to 999999\n",
      "Data columns (total 12 columns):\n",
      " #   Column         Non-Null Count    Dtype         \n",
      "---  ------         --------------    -----         \n",
      " 0   categories     1000000 non-null  object        \n",
      " 1   channel_id     1000000 non-null  object        \n",
      " 2   crawl_date     1000000 non-null  object        \n",
      " 3   description    1000000 non-null  object        \n",
      " 4   dislike_count  980320 non-null   float64       \n",
      " 5   display_id     1000000 non-null  object        \n",
      " 6   duration       1000000 non-null  int64         \n",
      " 7   like_count     980320 non-null   float64       \n",
      " 8   tags           1000000 non-null  object        \n",
      " 9   title          1000000 non-null  object        \n",
      " 10  upload_date    1000000 non-null  datetime64[ns]\n",
      " 11  view_count     999999 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float64(3), int64(1), object(7)\n",
      "memory usage: 91.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df_tags.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data_path = \"data/data-ssd/full/\" \n",
    "\n",
    "dfs = []\n",
    "for df_tags in pd.read_json(data_path+'yt_metadata_en.jsonl.gz', compression=\"infer\", chunksize=1000000, lines=True):\n",
    "    df_tags.drop(columns=['categories', 'channel_id', 'crawl_date', 'description', 'dislike_count', 'like_count', 'view_count', 'upload_date'], inplace=True)\n",
    "\n",
    "    dfs.append(df_tags)\n",
    "df_tags = pd.concat(dfs)\n",
    "\n",
    "df_tags.to_feather(data_path+'yt_metadata_tags.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 72924794 entries, 0 to 72924793\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Dtype \n",
      "---  ------      ----- \n",
      " 0   display_id  object\n",
      " 1   duration    int64 \n",
      " 2   tags        object\n",
      " 3   title       object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 2.2+ GB\n"
     ]
    }
   ],
   "source": [
    "df_tags.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_tags.drop(columns=['display_id', 'duration'], inplace=True) # turns out this is more expensive than useful....\n",
    "#df_tags.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 72924794 entries, 0 to 72924793\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Dtype \n",
      "---  ------      ----- \n",
      " 0   display_id  object\n",
      " 1   duration    int64 \n",
      " 2   tags        object\n",
      " 3   title       object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 2.2+ GB\n"
     ]
    }
   ],
   "source": [
    "data_path = \"data/data-ssd/full/\" \n",
    "df_tags = pd.read_feather(path= data_path + \"yt_metadata_tags.feather\", use_threads=True)\n",
    "df_tags.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 72924794 entries, 0 to 72924793\n",
      "Series name: tags\n",
      "Non-Null Count     Dtype \n",
      "--------------     ----- \n",
      "72924794 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 556.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df_tags = df_tags['tags']\n",
    "df_tags.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tags.to_frame().to_feather(data_path+'yt_metadata_tags.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    lego city,lego police,lego city police,lego ci...\n",
       "1    Lego superheroes,lego hulk,hulk smash,lego mar...\n",
       "2    lego city,lego police,lego city police,lego fi...\n",
       "3    Lego harry potter,new harry potter,harry potte...\n",
       "4    lego city,lego police,lego city police,lego fi...\n",
       "Name: tags, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tags.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorization of tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# gensim\n",
    "import gensim\n",
    "from gensim.models import Word2Vec, KeyedVectors, FastText, doc2vec\n",
    "import gensim.downloader as api\n",
    "from gensim.models.phrases import Phrases\n",
    "# nltk\n",
    "# import nltk\n",
    "# from nltk.corpus import stopwords\n",
    "# from nltk.tokenize import word_tokenize\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__testing_word2vec-matrix-synopsis: [THIS IS ONLY FOR TESTING] Word vecrors ...\n",
      "conceptnet-numberbatch-17-06-300: ConceptNet Numberbatch consists of state...\n",
      "fasttext-wiki-news-subwords-300: 1 million word vectors trained on Wikipe...\n",
      "glove-twitter-100: Pre-trained vectors based on  2B tweets,...\n",
      "glove-twitter-200: Pre-trained vectors based on 2B tweets, ...\n",
      "glove-twitter-25: Pre-trained vectors based on 2B tweets, ...\n",
      "glove-twitter-50: Pre-trained vectors based on 2B tweets, ...\n",
      "glove-wiki-gigaword-100: Pre-trained vectors based on Wikipedia 2...\n",
      "glove-wiki-gigaword-200: Pre-trained vectors based on Wikipedia 2...\n",
      "glove-wiki-gigaword-300: Pre-trained vectors based on Wikipedia 2...\n",
      "glove-wiki-gigaword-50: Pre-trained vectors based on Wikipedia 2...\n",
      "word2vec-google-news-300: Pre-trained vectors trained on a part of...\n",
      "word2vec-ruscorpora-300: Word2vec Continuous Skipgram vectors tra...\n"
     ]
    }
   ],
   "source": [
    "for model_name, model_data in sorted(api.info()['models'].items()):\n",
    "    print(\"{}: {}\".format(model_name, model_data['description'][:40] + \"...\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('dog', 0.9218006134033203), ('rabbit', 0.8487821817398071), ('monkey', 0.8041081428527832), ('rat', 0.7891963720321655), ('cats', 0.7865270376205444), ('snake', 0.7798910737037659), ('dogs', 0.7795815467834473), ('pet', 0.7792249917984009), ('mouse', 0.7731667757034302), ('bite', 0.7728800177574158)]\n"
     ]
    }
   ],
   "source": [
    "glove = api.load(\"glove-wiki-gigaword-50\")\n",
    "print(glove.most_similar(\"cat\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('myspace', 0.8685212135314941), ('uploaded', 0.8573760986328125), ('facebook', 0.8540773391723633), ('twitter', 0.8430657982826233), ('videos', 0.8099467158317566), ('video', 0.7907883524894714), ('downloaded', 0.7642441391944885), ('blog', 0.7627186179161072), ('download', 0.7616114020347595), ('downloads', 0.7580808401107788)]\n"
     ]
    }
   ],
   "source": [
    "print(glove.most_similar(\"youtube\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('yahoo', 0.8942785263061523), ('aol', 0.852712869644165), ('microsoft', 0.8450709581375122), ('internet', 0.8179759979248047), ('web', 0.8175380229949951), ('facebook', 0.8087005615234375), ('ebay', 0.7930072546005249), ('netscape', 0.7912958860397339), ('online', 0.7908353805541992), ('software', 0.7816097140312195)]\n"
     ]
    }
   ],
   "source": [
    "print(glove.most_similar(\"google\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('mindstorms', 0.828197181224823), ('bionicle', 0.7207260131835938), ('jigsaw', 0.6471174955368042), ('dolls', 0.6425037980079651), ('technic', 0.6417526006698608), ('namco', 0.6410648226737976), ('diecast', 0.638368546962738), ('arcade', 0.6373211145401001), ('toy', 0.6369045376777649), ('playmobil', 0.6331797242164612)]\n"
     ]
    }
   ],
   "source": [
    "print(glove.most_similar(\"lego\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('blackberry', 0.7543067932128906), ('chips', 0.7438643574714661), ('iphone', 0.7429664134979248), ('microsoft', 0.7334205508232117), ('ipad', 0.7331036925315857), ('pc', 0.7217226624488831), ('ipod', 0.7199784517288208), ('intel', 0.7192243337631226), ('ibm', 0.7146540880203247), ('software', 0.7093585729598999)]\n"
     ]
    }
   ],
   "source": [
    "print(glove.most_similar(\"apple\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog\n"
     ]
    }
   ],
   "source": [
    "print(glove.most_similar_to_given(\"cat\", [\"dog\", \"mouse\", \"lego\", \"apple\", \"youtube\", \"google\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lego city',\n",
       " 'lego police',\n",
       " 'lego city police',\n",
       " 'lego city episodes',\n",
       " 'videos de lego city',\n",
       " 'lego policia',\n",
       " 'lego bomberos',\n",
       " 'lego fire truck',\n",
       " 'lego firetruck',\n",
       " 'lego police chase',\n",
       " 'lego robbers',\n",
       " 'lego cartoons',\n",
       " 'lego movies',\n",
       " 'lego videos for kids']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fine-tune the model with our tags\n",
    "df_tags.head().apply(lambda x: x.split(\",\"))[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_tags' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m#df_tags = df_tags.apply(lambda x: x.split(\",\")) # jesus christ everything takes forever, 30min for this + all the memory\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df_tags\u001b[39m.\u001b[39mhead()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_tags' is not defined"
     ]
    }
   ],
   "source": [
    "#df_tags = df_tags.apply(lambda x: x.split(\",\")) # jesus christ everything takes forever, 30min for this + all the memory\n",
    "df_tags.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modin\n",
    "import modin.pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KilledWorker",
     "evalue": "('parse-c1a3ed1b9b8f3ff7b997c3767e86224f', <WorkerState 'tcp://127.0.0.1:56296', name: 2, status: closed, memory: 0, processing: 1>)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKilledWorker\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [7], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# load with modin\u001b[39;00m\n\u001b[1;32m      2\u001b[0m data_path \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdata/data-ssd/full/\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m df_tags \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_feather(path\u001b[39m=\u001b[39;49m data_path \u001b[39m+\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39myt_metadata_tags.feather\u001b[39;49m\u001b[39m\"\u001b[39;49m, use_threads\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/modin/logging/logger_function.py:65\u001b[0m, in \u001b[0;36mlogger_decorator.<locals>.decorator.<locals>.run_and_log\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[39mCompute function with logging if Modin logging is enabled.\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[39mAny\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mif\u001b[39;00m LogMode\u001b[39m.\u001b[39mget() \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdisable\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     67\u001b[0m logger \u001b[39m=\u001b[39m get_logger()\n\u001b[1;32m     68\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/modin/pandas/io.py:439\u001b[0m, in \u001b[0;36mread_feather\u001b[0;34m(path, columns, use_threads, storage_options)\u001b[0m\n\u001b[1;32m    436\u001b[0m Engine\u001b[39m.\u001b[39msubscribe(_update_engine)\n\u001b[1;32m    437\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmodin\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexecution\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdispatching\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfactories\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdispatcher\u001b[39;00m \u001b[39mimport\u001b[39;00m FactoryDispatcher\n\u001b[0;32m--> 439\u001b[0m \u001b[39mreturn\u001b[39;00m DataFrame(query_compiler\u001b[39m=\u001b[39mFactoryDispatcher\u001b[39m.\u001b[39;49mread_feather(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs))\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/modin/core/execution/dispatching/factories/dispatcher.py:232\u001b[0m, in \u001b[0;36mFactoryDispatcher.read_feather\u001b[0;34m(cls, **kwargs)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    230\u001b[0m \u001b[39m@_inherit_docstrings\u001b[39m(factories\u001b[39m.\u001b[39mBaseFactory\u001b[39m.\u001b[39m_read_feather)\n\u001b[1;32m    231\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mread_feather\u001b[39m(\u001b[39mcls\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 232\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m__factory\u001b[39m.\u001b[39;49m_read_feather(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/modin/core/execution/dispatching/factories/factories.py:287\u001b[0m, in \u001b[0;36mBaseFactory._read_feather\u001b[0;34m(cls, **kwargs)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    280\u001b[0m \u001b[39m@doc\u001b[39m(\n\u001b[1;32m    281\u001b[0m     _doc_io_method_template,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    285\u001b[0m )\n\u001b[1;32m    286\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_read_feather\u001b[39m(\u001b[39mcls\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 287\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mio_cls\u001b[39m.\u001b[39;49mread_feather(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/modin/logging/logger_function.py:65\u001b[0m, in \u001b[0;36mlogger_decorator.<locals>.decorator.<locals>.run_and_log\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[39mCompute function with logging if Modin logging is enabled.\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[39mAny\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mif\u001b[39;00m LogMode\u001b[39m.\u001b[39mget() \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdisable\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     67\u001b[0m logger \u001b[39m=\u001b[39m get_logger()\n\u001b[1;32m     68\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/modin/core/io/file_dispatcher.py:153\u001b[0m, in \u001b[0;36mFileDispatcher.read\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    130\u001b[0m \u001b[39m@logger_decorator\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mPANDAS-API\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mFileDispatcher.read\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mINFO\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    131\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mread\u001b[39m(\u001b[39mcls\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    132\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    133\u001b[0m \u001b[39m    Read data according passed `args` and `kwargs`.\u001b[39;00m\n\u001b[1;32m    134\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[39m    postprocessing work on the resulting query_compiler object.\u001b[39;00m\n\u001b[1;32m    152\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 153\u001b[0m     query_compiler \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_read(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    154\u001b[0m     \u001b[39m# TODO (devin-petersohn): Make this section more general for non-pandas kernel\u001b[39;00m\n\u001b[1;32m    155\u001b[0m     \u001b[39m# implementations.\u001b[39;00m\n\u001b[1;32m    156\u001b[0m     \u001b[39mif\u001b[39;00m StorageFormat\u001b[39m.\u001b[39mget() \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mPandas\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/modin/core/io/column_stores/feather_dispatcher.py:64\u001b[0m, in \u001b[0;36mFeatherDispatcher._read\u001b[0;34m(cls, path, columns, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[39m# pyarrow.feather.read_feather doesn't support columns as pandas.Index\u001b[39;00m\n\u001b[1;32m     63\u001b[0m     columns \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(df\u001b[39m.\u001b[39mcolumns)\n\u001b[0;32m---> 64\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mbuild_query_compiler(path, columns, use_threads\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/modin/core/io/column_stores/column_store_dispatcher.py:219\u001b[0m, in \u001b[0;36mColumnStoreDispatcher.build_query_compiler\u001b[0;34m(cls, path, columns, **kwargs)\u001b[0m\n\u001b[1;32m    217\u001b[0m col_partitions, column_widths \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mbuild_columns(columns)\n\u001b[1;32m    218\u001b[0m partition_ids \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mcall_deploy(path, col_partitions, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 219\u001b[0m index, row_lens \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mbuild_index(partition_ids)\n\u001b[1;32m    220\u001b[0m remote_parts \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mbuild_partition(partition_ids[:\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m], row_lens, column_widths)\n\u001b[1;32m    221\u001b[0m dtypes \u001b[39m=\u001b[39m (\n\u001b[1;32m    222\u001b[0m     \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mbuild_dtypes(partition_ids[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m], columns)\n\u001b[1;32m    223\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(partition_ids) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    224\u001b[0m     \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    225\u001b[0m )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/modin/core/io/column_stores/column_store_dispatcher.py:124\u001b[0m, in \u001b[0;36mColumnStoreDispatcher.build_index\u001b[0;34m(cls, partition_ids)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    108\u001b[0m \u001b[39mCompute index and its split sizes of resulting Modin DataFrame.\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[39m    List with lengths of index chunks.\u001b[39;00m\n\u001b[1;32m    121\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    122\u001b[0m num_partitions \u001b[39m=\u001b[39m NPartitions\u001b[39m.\u001b[39mget()\n\u001b[1;32m    123\u001b[0m index_len \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 124\u001b[0m     \u001b[39m0\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(partition_ids) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mmaterialize(partition_ids[\u001b[39m-\u001b[39;49m\u001b[39m2\u001b[39;49m][\u001b[39m0\u001b[39;49m])\n\u001b[1;32m    125\u001b[0m )\n\u001b[1;32m    126\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(index_len, \u001b[39mint\u001b[39m):\n\u001b[1;32m    127\u001b[0m     index \u001b[39m=\u001b[39m pandas\u001b[39m.\u001b[39mRangeIndex(index_len)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/modin/core/execution/dask/common/engine_wrapper.py:70\u001b[0m, in \u001b[0;36mDaskWrapper.materialize\u001b[0;34m(cls, future)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[39mMaterialize data matching `future` object.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[39m    An object(s) from the distributed memory.\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     69\u001b[0m client \u001b[39m=\u001b[39m default_client()\n\u001b[0;32m---> 70\u001b[0m \u001b[39mreturn\u001b[39;00m client\u001b[39m.\u001b[39;49mgather(future)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/distributed/client.py:1969\u001b[0m, in \u001b[0;36mClient.gather\u001b[0;34m(self, futures, errors, direct, asynchronous)\u001b[0m\n\u001b[1;32m   1967\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1968\u001b[0m     local_worker \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1969\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msync(\n\u001b[1;32m   1970\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_gather,\n\u001b[1;32m   1971\u001b[0m     futures,\n\u001b[1;32m   1972\u001b[0m     errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m   1973\u001b[0m     direct\u001b[39m=\u001b[39;49mdirect,\n\u001b[1;32m   1974\u001b[0m     local_worker\u001b[39m=\u001b[39;49mlocal_worker,\n\u001b[1;32m   1975\u001b[0m     asynchronous\u001b[39m=\u001b[39;49masynchronous,\n\u001b[1;32m   1976\u001b[0m )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/distributed/client.py:865\u001b[0m, in \u001b[0;36mClient.sync\u001b[0;34m(self, func, asynchronous, callback_timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m    863\u001b[0m     \u001b[39mreturn\u001b[39;00m future\n\u001b[1;32m    864\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 865\u001b[0m     \u001b[39mreturn\u001b[39;00m sync(\n\u001b[1;32m    866\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloop, func, \u001b[39m*\u001b[39;49margs, callback_timeout\u001b[39m=\u001b[39;49mcallback_timeout, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    867\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/distributed/utils.py:327\u001b[0m, in \u001b[0;36msync\u001b[0;34m(loop, func, callback_timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[39mif\u001b[39;00m error[\u001b[39m0\u001b[39m]:\n\u001b[1;32m    326\u001b[0m     typ, exc, tb \u001b[39m=\u001b[39m error[\u001b[39m0\u001b[39m]\n\u001b[0;32m--> 327\u001b[0m     \u001b[39mraise\u001b[39;00m exc\u001b[39m.\u001b[39mwith_traceback(tb)\n\u001b[1;32m    328\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    329\u001b[0m     \u001b[39mreturn\u001b[39;00m result[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/distributed/utils.py:310\u001b[0m, in \u001b[0;36msync.<locals>.f\u001b[0;34m()\u001b[0m\n\u001b[1;32m    308\u001b[0m     \u001b[39mif\u001b[39;00m callback_timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    309\u001b[0m         future \u001b[39m=\u001b[39m asyncio\u001b[39m.\u001b[39mwait_for(future, callback_timeout)\n\u001b[0;32m--> 310\u001b[0m     result[\u001b[39m0\u001b[39m] \u001b[39m=\u001b[39m \u001b[39myield\u001b[39;00m future\n\u001b[1;32m    311\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m    312\u001b[0m     error[\u001b[39m0\u001b[39m] \u001b[39m=\u001b[39m sys\u001b[39m.\u001b[39mexc_info()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/tornado/gen.py:769\u001b[0m, in \u001b[0;36mRunner.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    766\u001b[0m exc_info \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    768\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 769\u001b[0m     value \u001b[39m=\u001b[39m future\u001b[39m.\u001b[39;49mresult()\n\u001b[1;32m    770\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m    771\u001b[0m     exc_info \u001b[39m=\u001b[39m sys\u001b[39m.\u001b[39mexc_info()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/distributed/client.py:1834\u001b[0m, in \u001b[0;36mClient._gather\u001b[0;34m(self, futures, errors, direct, local_worker)\u001b[0m\n\u001b[1;32m   1832\u001b[0m         exc \u001b[39m=\u001b[39m CancelledError(key)\n\u001b[1;32m   1833\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1834\u001b[0m         \u001b[39mraise\u001b[39;00m exception\u001b[39m.\u001b[39mwith_traceback(traceback)\n\u001b[1;32m   1835\u001b[0m     \u001b[39mraise\u001b[39;00m exc\n\u001b[1;32m   1836\u001b[0m \u001b[39mif\u001b[39;00m errors \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mskip\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "\u001b[0;31mKilledWorker\u001b[0m: ('parse-c1a3ed1b9b8f3ff7b997c3767e86224f', <WorkerState 'tcp://127.0.0.1:56296', name: 2, status: closed, memory: 0, processing: 1>)"
     ]
    }
   ],
   "source": [
    "# load with modin\n",
    "data_path = \"data/data-ssd/full/\"\n",
    "df_tags = pd.read_feather(path= data_path + \"yt_metadata_tags.feather\", use_threads=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove.build_vocab(df_tags, update=True)\n",
    "glove.train(df_tags, total_examples=glove.corpus_count, epochs=glove.epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ada",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ac29d0fc6b0188101944722695454f1e9e17731afb2c274abaf6b8203f21da01"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
