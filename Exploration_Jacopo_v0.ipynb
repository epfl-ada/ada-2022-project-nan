{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration Notebook v0 - Jacopo\n",
    "\n",
    "To avoid cluttering the main notebook, I'm going to do some exploration here, it might get very messy as a whole but it should be easy to follow.\n",
    "\n",
    "This will probably be the first (zero) version of several notebooks. The version names should help with keeping track and I will name them -Jacopo to avoid confusion with the main notebook.\n",
    "\n",
    "## Folder Structure\n",
    "- `./`: Notebooks, Readme, gitignore and Data are in the root folder\n",
    "- `data/ `: all data in this folder, will be ignored by git but it will eventually include quite a lot, subfolders like `out/` for results, `data-ssd/` for YouNiverse dataset symlinked to an ssd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>categories</th>\n",
       "      <th>channel_id</th>\n",
       "      <th>dislike_count</th>\n",
       "      <th>display_id</th>\n",
       "      <th>duration</th>\n",
       "      <th>like_count</th>\n",
       "      <th>upload_date</th>\n",
       "      <th>view_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Film &amp; Animation</td>\n",
       "      <td>UCzWrhkg9eK5I8Bm3HfV-unA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>SBqSc91Hn9g</td>\n",
       "      <td>1159</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2016-09-28</td>\n",
       "      <td>1057.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Film &amp; Animation</td>\n",
       "      <td>UCzWrhkg9eK5I8Bm3HfV-unA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>UuugEl86ESY</td>\n",
       "      <td>2681</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2016-09-28</td>\n",
       "      <td>12894.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Film &amp; Animation</td>\n",
       "      <td>UCzWrhkg9eK5I8Bm3HfV-unA</td>\n",
       "      <td>779.0</td>\n",
       "      <td>oB4c-yvnbjs</td>\n",
       "      <td>1394</td>\n",
       "      <td>1607.0</td>\n",
       "      <td>2016-09-28</td>\n",
       "      <td>1800602.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Film &amp; Animation</td>\n",
       "      <td>UCzWrhkg9eK5I8Bm3HfV-unA</td>\n",
       "      <td>24.0</td>\n",
       "      <td>ZaV-gTCMV8E</td>\n",
       "      <td>5064</td>\n",
       "      <td>227.0</td>\n",
       "      <td>2016-09-28</td>\n",
       "      <td>57640.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Film &amp; Animation</td>\n",
       "      <td>UCzWrhkg9eK5I8Bm3HfV-unA</td>\n",
       "      <td>13.0</td>\n",
       "      <td>cGvL7AvMfM0</td>\n",
       "      <td>3554</td>\n",
       "      <td>105.0</td>\n",
       "      <td>2016-09-28</td>\n",
       "      <td>86368.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         categories                channel_id  dislike_count   display_id  \\\n",
       "0  Film & Animation  UCzWrhkg9eK5I8Bm3HfV-unA            1.0  SBqSc91Hn9g   \n",
       "1  Film & Animation  UCzWrhkg9eK5I8Bm3HfV-unA            1.0  UuugEl86ESY   \n",
       "2  Film & Animation  UCzWrhkg9eK5I8Bm3HfV-unA          779.0  oB4c-yvnbjs   \n",
       "3  Film & Animation  UCzWrhkg9eK5I8Bm3HfV-unA           24.0  ZaV-gTCMV8E   \n",
       "4  Film & Animation  UCzWrhkg9eK5I8Bm3HfV-unA           13.0  cGvL7AvMfM0   \n",
       "\n",
       "   duration  like_count upload_date  view_count  \n",
       "0      1159         8.0  2016-09-28      1057.0  \n",
       "1      2681        23.0  2016-09-28     12894.0  \n",
       "2      1394      1607.0  2016-09-28   1800602.0  \n",
       "3      5064       227.0  2016-09-28     57640.0  \n",
       "4      3554       105.0  2016-09-28     86368.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = \"data/data-ssd/full/\" \n",
    "\n",
    "#first of all let's create a 100k randomized sample for the bigger datasets so we can work with them nicely\n",
    "import random\n",
    "skip_rows = lambda i: i>0 and random.random() < 0.8\n",
    "#df_metadata = pd.read_json(data_path + \"yt_metadata_en.jsonl.gz\", lines=True, compression=\"gzip\", encoding=\"utf-8\", nrows=100000)\n",
    "df_metadata = pd.read_feather(path= data_path + \"yt_metadata_helper.feather\", use_threads=True)\n",
    "df_metadata.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 72924794 entries, 0 to 72924793\n",
      "Data columns (total 8 columns):\n",
      " #   Column         Dtype         \n",
      "---  ------         -----         \n",
      " 0   categories     object        \n",
      " 1   channel_id     object        \n",
      " 2   dislike_count  float64       \n",
      " 3   display_id     object        \n",
      " 4   duration       int64         \n",
      " 5   like_count     float64       \n",
      " 6   upload_date    datetime64[ns]\n",
      " 7   view_count     float64       \n",
      "dtypes: datetime64[ns](1), float64(3), int64(1), object(3)\n",
      "memory usage: 4.3+ GB\n"
     ]
    }
   ],
   "source": [
    "df_metadata.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 72924794 entries, 0 to 72924793\n",
      "Data columns (total 8 columns):\n",
      " #   Column         Dtype         \n",
      "---  ------         -----         \n",
      " 0   categories     object        \n",
      " 1   channel_id     object        \n",
      " 2   dislike_count  int16         \n",
      " 3   display_id     object        \n",
      " 4   duration       int16         \n",
      " 5   like_count     int16         \n",
      " 6   upload_date    datetime64[ns]\n",
      " 7   view_count     int32         \n",
      "dtypes: datetime64[ns](1), int16(3), int32(1), object(3)\n",
      "memory usage: 2.9+ GB\n"
     ]
    }
   ],
   "source": [
    "df_metadata['dislike_count'] = df_metadata['dislike_count'].notna().astype('int16')\n",
    "df_metadata['like_count'] = df_metadata['like_count'].notna().astype('int16')\n",
    "df_metadata['view_count'] = df_metadata['view_count'].notna().astype('int32')\n",
    "df_metadata['duration'] = df_metadata['duration'].notna().astype('int16')\n",
    "df_metadata.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save pickle\n",
    "import pickle\n",
    "with open(data_path + \"yt_metadata_helper.pkl\", \"wb\") as f:\n",
    "    pickle.dump(df_metadata, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>categories</th>\n",
       "      <th>channel_id</th>\n",
       "      <th>dislike_count</th>\n",
       "      <th>display_id</th>\n",
       "      <th>duration</th>\n",
       "      <th>like_count</th>\n",
       "      <th>upload_date</th>\n",
       "      <th>view_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>UCzWrhkg9eK5I8Bm3HfV-unA</td>\n",
       "      <td>1</td>\n",
       "      <td>SBqSc91Hn9g</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-09-28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>UCzWrhkg9eK5I8Bm3HfV-unA</td>\n",
       "      <td>1</td>\n",
       "      <td>UuugEl86ESY</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-09-28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>UCzWrhkg9eK5I8Bm3HfV-unA</td>\n",
       "      <td>1</td>\n",
       "      <td>oB4c-yvnbjs</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-09-28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>UCzWrhkg9eK5I8Bm3HfV-unA</td>\n",
       "      <td>1</td>\n",
       "      <td>ZaV-gTCMV8E</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-09-28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>UCzWrhkg9eK5I8Bm3HfV-unA</td>\n",
       "      <td>1</td>\n",
       "      <td>cGvL7AvMfM0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-09-28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   categories                channel_id  dislike_count   display_id  duration  \\\n",
       "0           5  UCzWrhkg9eK5I8Bm3HfV-unA              1  SBqSc91Hn9g         1   \n",
       "1           5  UCzWrhkg9eK5I8Bm3HfV-unA              1  UuugEl86ESY         1   \n",
       "2           5  UCzWrhkg9eK5I8Bm3HfV-unA              1  oB4c-yvnbjs         1   \n",
       "3           5  UCzWrhkg9eK5I8Bm3HfV-unA              1  ZaV-gTCMV8E         1   \n",
       "4           5  UCzWrhkg9eK5I8Bm3HfV-unA              1  cGvL7AvMfM0         1   \n",
       "\n",
       "   like_count upload_date  view_count  \n",
       "0           1  2016-09-28           1  \n",
       "1           1  2016-09-28           1  \n",
       "2           1  2016-09-28           1  \n",
       "3           1  2016-09-28           1  \n",
       "4           1  2016-09-28           1  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "df_metadata['categories'] = le.fit_transform(df_metadata['categories'])\n",
    "df_metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6     13720303\n",
      "4     12276397\n",
      "10     8881022\n",
      "9      8305003\n",
      "12     6910666\n",
      "16     4354412\n",
      "7      3968127\n",
      "3      3795564\n",
      "14     2403004\n",
      "5      2359736\n",
      "1      2256967\n",
      "2      1172503\n",
      "17     1096565\n",
      "11      777449\n",
      "13      645508\n",
      "0         1522\n",
      "15          41\n",
      "8            5\n",
      "Name: categories, dtype: int64\n",
      "['' 'Autos & Vehicles' 'Comedy' 'Education' 'Entertainment'\n",
      " 'Film & Animation' 'Gaming' 'Howto & Style' 'Movies' 'Music'\n",
      " 'News & Politics' 'Nonprofits & Activism' 'People & Blogs'\n",
      " 'Pets & Animals' 'Science & Technology' 'Shows' 'Sports'\n",
      " 'Travel & Events']\n"
     ]
    }
   ],
   "source": [
    "print(df_metadata['categories'].value_counts())\n",
    "print(le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 72924794 entries, 0 to 72924793\n",
      "Data columns (total 8 columns):\n",
      " #   Column         Dtype         \n",
      "---  ------         -----         \n",
      " 0   categories     int8          \n",
      " 1   channel_id     object        \n",
      " 2   dislike_count  int16         \n",
      " 3   display_id     object        \n",
      " 4   duration       int16         \n",
      " 5   like_count     int16         \n",
      " 6   upload_date    datetime64[ns]\n",
      " 7   view_count     int32         \n",
      "dtypes: datetime64[ns](1), int16(3), int32(1), int8(1), object(2)\n",
      "memory usage: 2.4+ GB\n"
     ]
    }
   ],
   "source": [
    "df_metadata['categories'] = df_metadata['categories'].astype('int8')\n",
    "df_metadata.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save pickle\n",
    "import pickle\n",
    "with open(data_path + \"yt_metadata_helper.pkl\", \"wb\") as f:\n",
    "    pickle.dump(df_metadata, f)\n",
    "\n",
    "# save categories\n",
    "with open(data_path + \"categories.pkl\", \"wb\") as f:\n",
    "    pickle.dump(le.classes_, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>categories</th>\n",
       "      <th>channel_id</th>\n",
       "      <th>dislike_count</th>\n",
       "      <th>display_id</th>\n",
       "      <th>duration</th>\n",
       "      <th>like_count</th>\n",
       "      <th>upload_date</th>\n",
       "      <th>view_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>UCzWrhkg9eK5I8Bm3HfV-unA</td>\n",
       "      <td>1</td>\n",
       "      <td>SBqSc91Hn9g</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-09-28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>UCzWrhkg9eK5I8Bm3HfV-unA</td>\n",
       "      <td>1</td>\n",
       "      <td>UuugEl86ESY</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-09-28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>UCzWrhkg9eK5I8Bm3HfV-unA</td>\n",
       "      <td>1</td>\n",
       "      <td>oB4c-yvnbjs</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-09-28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>UCzWrhkg9eK5I8Bm3HfV-unA</td>\n",
       "      <td>1</td>\n",
       "      <td>ZaV-gTCMV8E</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-09-28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>UCzWrhkg9eK5I8Bm3HfV-unA</td>\n",
       "      <td>1</td>\n",
       "      <td>cGvL7AvMfM0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-09-28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   categories                channel_id  dislike_count   display_id  duration  \\\n",
       "0           5  UCzWrhkg9eK5I8Bm3HfV-unA              1  SBqSc91Hn9g         1   \n",
       "1           5  UCzWrhkg9eK5I8Bm3HfV-unA              1  UuugEl86ESY         1   \n",
       "2           5  UCzWrhkg9eK5I8Bm3HfV-unA              1  oB4c-yvnbjs         1   \n",
       "3           5  UCzWrhkg9eK5I8Bm3HfV-unA              1  ZaV-gTCMV8E         1   \n",
       "4           5  UCzWrhkg9eK5I8Bm3HfV-unA              1  cGvL7AvMfM0         1   \n",
       "\n",
       "   like_count upload_date  view_count  \n",
       "0           1  2016-09-28           1  \n",
       "1           1  2016-09-28           1  \n",
       "2           1  2016-09-28           1  \n",
       "3           1  2016-09-28           1  \n",
       "4           1  2016-09-28           1  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2018    15275859\n",
       "2019    12723124\n",
       "2017    12486407\n",
       "2016     9352771\n",
       "2015     6808073\n",
       "2014     5179935\n",
       "2013     4018279\n",
       "2012     2926436\n",
       "2011     1874984\n",
       "2010     1085424\n",
       "2009      694586\n",
       "2008      338040\n",
       "2007      137250\n",
       "2006       23294\n",
       "2005         332\n",
       "Name: upload_date, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_metadata['upload_date'].dt.year.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>categories</th>\n",
       "      <th>channel_id</th>\n",
       "      <th>crawl_date</th>\n",
       "      <th>description</th>\n",
       "      <th>dislike_count</th>\n",
       "      <th>display_id</th>\n",
       "      <th>duration</th>\n",
       "      <th>like_count</th>\n",
       "      <th>tags</th>\n",
       "      <th>title</th>\n",
       "      <th>upload_date</th>\n",
       "      <th>view_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Film &amp; Animation</td>\n",
       "      <td>UCzWrhkg9eK5I8Bm3HfV-unA</td>\n",
       "      <td>2019-10-31 20:19:26.270363</td>\n",
       "      <td>Lego City Police Lego Firetruck Cartoons about...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>SBqSc91Hn9g</td>\n",
       "      <td>1159</td>\n",
       "      <td>8.0</td>\n",
       "      <td>lego city,lego police,lego city police,lego ci...</td>\n",
       "      <td>Lego City Police Lego Firetruck Cartoons about...</td>\n",
       "      <td>2016-09-28</td>\n",
       "      <td>1057.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Film &amp; Animation</td>\n",
       "      <td>UCzWrhkg9eK5I8Bm3HfV-unA</td>\n",
       "      <td>2019-10-31 20:19:26.914516</td>\n",
       "      <td>Lego Marvel SuperHeroes Lego Hulk Smash Iron-M...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>UuugEl86ESY</td>\n",
       "      <td>2681</td>\n",
       "      <td>23.0</td>\n",
       "      <td>Lego superheroes,lego hulk,hulk smash,lego mar...</td>\n",
       "      <td>Lego Marvel SuperHeroes Lego Hulk Smash Iron-M...</td>\n",
       "      <td>2016-09-28</td>\n",
       "      <td>12894.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Film &amp; Animation</td>\n",
       "      <td>UCzWrhkg9eK5I8Bm3HfV-unA</td>\n",
       "      <td>2019-10-31 20:19:26.531203</td>\n",
       "      <td>Lego City Police Lego Fireman Cartoons about L...</td>\n",
       "      <td>779.0</td>\n",
       "      <td>oB4c-yvnbjs</td>\n",
       "      <td>1394</td>\n",
       "      <td>1607.0</td>\n",
       "      <td>lego city,lego police,lego city police,lego fi...</td>\n",
       "      <td>Lego City Police Lego Fireman Cartoons about L...</td>\n",
       "      <td>2016-09-28</td>\n",
       "      <td>1800602.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Film &amp; Animation</td>\n",
       "      <td>UCzWrhkg9eK5I8Bm3HfV-unA</td>\n",
       "      <td>2019-10-31 20:19:28.335329</td>\n",
       "      <td>Lego Harry Potter Complete Lego New Movie for ...</td>\n",
       "      <td>24.0</td>\n",
       "      <td>ZaV-gTCMV8E</td>\n",
       "      <td>5064</td>\n",
       "      <td>227.0</td>\n",
       "      <td>Lego harry potter,new harry potter,harry potte...</td>\n",
       "      <td>Lego Harry Potter Complete Lego New Movie for ...</td>\n",
       "      <td>2016-09-28</td>\n",
       "      <td>57640.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Film &amp; Animation</td>\n",
       "      <td>UCzWrhkg9eK5I8Bm3HfV-unA</td>\n",
       "      <td>2019-10-31 20:19:30.328487</td>\n",
       "      <td>Lego City Police LONG VIDEO for kids Lego Fire...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>cGvL7AvMfM0</td>\n",
       "      <td>3554</td>\n",
       "      <td>105.0</td>\n",
       "      <td>lego city,lego police,lego city police,lego fi...</td>\n",
       "      <td>Lego City Police 1 HOUR LONG VIDEO for kids Le...</td>\n",
       "      <td>2016-09-28</td>\n",
       "      <td>86368.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         categories                channel_id                  crawl_date  \\\n",
       "0  Film & Animation  UCzWrhkg9eK5I8Bm3HfV-unA  2019-10-31 20:19:26.270363   \n",
       "1  Film & Animation  UCzWrhkg9eK5I8Bm3HfV-unA  2019-10-31 20:19:26.914516   \n",
       "2  Film & Animation  UCzWrhkg9eK5I8Bm3HfV-unA  2019-10-31 20:19:26.531203   \n",
       "3  Film & Animation  UCzWrhkg9eK5I8Bm3HfV-unA  2019-10-31 20:19:28.335329   \n",
       "4  Film & Animation  UCzWrhkg9eK5I8Bm3HfV-unA  2019-10-31 20:19:30.328487   \n",
       "\n",
       "                                         description  dislike_count  \\\n",
       "0  Lego City Police Lego Firetruck Cartoons about...            1.0   \n",
       "1  Lego Marvel SuperHeroes Lego Hulk Smash Iron-M...            1.0   \n",
       "2  Lego City Police Lego Fireman Cartoons about L...          779.0   \n",
       "3  Lego Harry Potter Complete Lego New Movie for ...           24.0   \n",
       "4  Lego City Police LONG VIDEO for kids Lego Fire...           13.0   \n",
       "\n",
       "    display_id  duration  like_count  \\\n",
       "0  SBqSc91Hn9g      1159         8.0   \n",
       "1  UuugEl86ESY      2681        23.0   \n",
       "2  oB4c-yvnbjs      1394      1607.0   \n",
       "3  ZaV-gTCMV8E      5064       227.0   \n",
       "4  cGvL7AvMfM0      3554       105.0   \n",
       "\n",
       "                                                tags  \\\n",
       "0  lego city,lego police,lego city police,lego ci...   \n",
       "1  Lego superheroes,lego hulk,hulk smash,lego mar...   \n",
       "2  lego city,lego police,lego city police,lego fi...   \n",
       "3  Lego harry potter,new harry potter,harry potte...   \n",
       "4  lego city,lego police,lego city police,lego fi...   \n",
       "\n",
       "                                               title upload_date  view_count  \n",
       "0  Lego City Police Lego Firetruck Cartoons about...  2016-09-28      1057.0  \n",
       "1  Lego Marvel SuperHeroes Lego Hulk Smash Iron-M...  2016-09-28     12894.0  \n",
       "2  Lego City Police Lego Fireman Cartoons about L...  2016-09-28   1800602.0  \n",
       "3  Lego Harry Potter Complete Lego New Movie for ...  2016-09-28     57640.0  \n",
       "4  Lego City Police 1 HOUR LONG VIDEO for kids Le...  2016-09-28     86368.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = \"data/data-ssd/full/\" \n",
    "# let's import the tags from the full dataset in order to encode them\n",
    "df_tags = pd.read_json(data_path + \"yt_metadata_en.jsonl.gz\", lines=True, compression=\"gzip\", encoding=\"utf-8\", \n",
    "dtype={'video_id': 'str', 'tags': 'str'}, nrows=1000000, convert_dates=['upload_date'])\n",
    "df_tags.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000000 entries, 0 to 999999\n",
      "Data columns (total 12 columns):\n",
      " #   Column         Non-Null Count    Dtype         \n",
      "---  ------         --------------    -----         \n",
      " 0   categories     1000000 non-null  object        \n",
      " 1   channel_id     1000000 non-null  object        \n",
      " 2   crawl_date     1000000 non-null  object        \n",
      " 3   description    1000000 non-null  object        \n",
      " 4   dislike_count  980320 non-null   float64       \n",
      " 5   display_id     1000000 non-null  object        \n",
      " 6   duration       1000000 non-null  int64         \n",
      " 7   like_count     980320 non-null   float64       \n",
      " 8   tags           1000000 non-null  object        \n",
      " 9   title          1000000 non-null  object        \n",
      " 10  upload_date    1000000 non-null  datetime64[ns]\n",
      " 11  view_count     999999 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float64(3), int64(1), object(7)\n",
      "memory usage: 91.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df_tags.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data_path = \"data/data-ssd/full/\" \n",
    "\n",
    "dfs = []\n",
    "for df_tags in pd.read_json(data_path+'yt_metadata_en.jsonl.gz', compression=\"infer\", chunksize=1000000, lines=True):\n",
    "    df_tags.drop(columns=['categories', 'channel_id', 'crawl_date', 'description', 'dislike_count', 'like_count', 'view_count', 'upload_date'], inplace=True)\n",
    "\n",
    "    dfs.append(df_tags)\n",
    "df_tags = pd.concat(dfs)\n",
    "\n",
    "df_tags.to_feather(data_path+'yt_metadata_tags.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 72924794 entries, 0 to 72924793\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Dtype \n",
      "---  ------      ----- \n",
      " 0   display_id  object\n",
      " 1   duration    int64 \n",
      " 2   tags        object\n",
      " 3   title       object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 2.2+ GB\n"
     ]
    }
   ],
   "source": [
    "df_tags.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_tags.drop(columns=['display_id', 'duration'], inplace=True) # turns out this is more expensive than useful....\n",
    "#df_tags.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 72924794 entries, 0 to 72924793\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Dtype \n",
      "---  ------      ----- \n",
      " 0   display_id  object\n",
      " 1   duration    int64 \n",
      " 2   tags        object\n",
      " 3   title       object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 2.2+ GB\n"
     ]
    }
   ],
   "source": [
    "data_path = \"data/data-ssd/full/\" \n",
    "df_tags = pd.read_feather(path= data_path + \"yt_metadata_tags.feather\", use_threads=True)\n",
    "df_tags.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 72924794 entries, 0 to 72924793\n",
      "Series name: tags\n",
      "Non-Null Count     Dtype \n",
      "--------------     ----- \n",
      "72924794 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 556.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df_tags = df_tags['tags']\n",
    "df_tags.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tags.to_frame().to_feather(data_path+'yt_metadata_tags.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    lego city,lego police,lego city police,lego ci...\n",
       "1    Lego superheroes,lego hulk,hulk smash,lego mar...\n",
       "2    lego city,lego police,lego city police,lego fi...\n",
       "3    Lego harry potter,new harry potter,harry potte...\n",
       "4    lego city,lego police,lego city police,lego fi...\n",
       "Name: tags, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tags.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorization of tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# gensim\n",
    "import gensim\n",
    "from gensim.models import Word2Vec, KeyedVectors, FastText, doc2vec\n",
    "import gensim.downloader as api\n",
    "from gensim.models.phrases import Phrases\n",
    "# nltk\n",
    "# import nltk\n",
    "# from nltk.corpus import stopwords\n",
    "# from nltk.tokenize import word_tokenize\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__testing_word2vec-matrix-synopsis: [THIS IS ONLY FOR TESTING] Word vecrors ...\n",
      "conceptnet-numberbatch-17-06-300: ConceptNet Numberbatch consists of state...\n",
      "fasttext-wiki-news-subwords-300: 1 million word vectors trained on Wikipe...\n",
      "glove-twitter-100: Pre-trained vectors based on  2B tweets,...\n",
      "glove-twitter-200: Pre-trained vectors based on 2B tweets, ...\n",
      "glove-twitter-25: Pre-trained vectors based on 2B tweets, ...\n",
      "glove-twitter-50: Pre-trained vectors based on 2B tweets, ...\n",
      "glove-wiki-gigaword-100: Pre-trained vectors based on Wikipedia 2...\n",
      "glove-wiki-gigaword-200: Pre-trained vectors based on Wikipedia 2...\n",
      "glove-wiki-gigaword-300: Pre-trained vectors based on Wikipedia 2...\n",
      "glove-wiki-gigaword-50: Pre-trained vectors based on Wikipedia 2...\n",
      "word2vec-google-news-300: Pre-trained vectors trained on a part of...\n",
      "word2vec-ruscorpora-300: Word2vec Continuous Skipgram vectors tra...\n"
     ]
    }
   ],
   "source": [
    "for model_name, model_data in sorted(api.info()['models'].items()):\n",
    "    print(\"{}: {}\".format(model_name, model_data['description'][:40] + \"...\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('dog', 0.9218006134033203), ('rabbit', 0.8487821817398071), ('monkey', 0.8041081428527832), ('rat', 0.7891963720321655), ('cats', 0.7865270376205444), ('snake', 0.7798910737037659), ('dogs', 0.7795815467834473), ('pet', 0.7792249917984009), ('mouse', 0.7731667757034302), ('bite', 0.7728800177574158)]\n"
     ]
    }
   ],
   "source": [
    "glove = api.load(\"glove-wiki-gigaword-50\")\n",
    "print(glove.most_similar(\"cat\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('myspace', 0.8685212135314941), ('uploaded', 0.8573760986328125), ('facebook', 0.8540773391723633), ('twitter', 0.8430657982826233), ('videos', 0.8099467158317566), ('video', 0.7907883524894714), ('downloaded', 0.7642441391944885), ('blog', 0.7627186179161072), ('download', 0.7616114020347595), ('downloads', 0.7580808401107788)]\n"
     ]
    }
   ],
   "source": [
    "print(glove.most_similar(\"youtube\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('yahoo', 0.8942785263061523), ('aol', 0.852712869644165), ('microsoft', 0.8450709581375122), ('internet', 0.8179759979248047), ('web', 0.8175380229949951), ('facebook', 0.8087005615234375), ('ebay', 0.7930072546005249), ('netscape', 0.7912958860397339), ('online', 0.7908353805541992), ('software', 0.7816097140312195)]\n"
     ]
    }
   ],
   "source": [
    "print(glove.most_similar(\"google\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('mindstorms', 0.828197181224823), ('bionicle', 0.7207260131835938), ('jigsaw', 0.6471174955368042), ('dolls', 0.6425037980079651), ('technic', 0.6417526006698608), ('namco', 0.6410648226737976), ('diecast', 0.638368546962738), ('arcade', 0.6373211145401001), ('toy', 0.6369045376777649), ('playmobil', 0.6331797242164612)]\n"
     ]
    }
   ],
   "source": [
    "print(glove.most_similar(\"lego\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('blackberry', 0.7543067932128906), ('chips', 0.7438643574714661), ('iphone', 0.7429664134979248), ('microsoft', 0.7334205508232117), ('ipad', 0.7331036925315857), ('pc', 0.7217226624488831), ('ipod', 0.7199784517288208), ('intel', 0.7192243337631226), ('ibm', 0.7146540880203247), ('software', 0.7093585729598999)]\n"
     ]
    }
   ],
   "source": [
    "print(glove.most_similar(\"apple\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog\n"
     ]
    }
   ],
   "source": [
    "print(glove.most_similar_to_given(\"cat\", [\"dog\", \"mouse\", \"lego\", \"apple\", \"youtube\", \"google\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lego city',\n",
       " 'lego police',\n",
       " 'lego city police',\n",
       " 'lego city episodes',\n",
       " 'videos de lego city',\n",
       " 'lego policia',\n",
       " 'lego bomberos',\n",
       " 'lego fire truck',\n",
       " 'lego firetruck',\n",
       " 'lego police chase',\n",
       " 'lego robbers',\n",
       " 'lego cartoons',\n",
       " 'lego movies',\n",
       " 'lego videos for kids']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fine-tune the model with our tags\n",
    "df_tags.head().apply(lambda x: x.split(\",\"))[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_tags' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m#df_tags = df_tags.apply(lambda x: x.split(\",\")) # jesus christ everything takes forever, 30min for this + all the memory\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df_tags\u001b[39m.\u001b[39mhead()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_tags' is not defined"
     ]
    }
   ],
   "source": [
    "#df_tags = df_tags.apply(lambda x: x.split(\",\")) # jesus christ everything takes forever, 30min for this + all the memory\n",
    "df_tags.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallelization with modin, ray, dask ... experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modin\n",
    "import modin.pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Dask execution environment not yet initialized. Initializing...\n",
      "To remove this warning, run the following python code before doing dataframe operations:\n",
      "\n",
      "    from distributed import Client\n",
      "\n",
      "    client = Client()\n",
      "\n",
      "distributed.diskutils - INFO - Found stale lock file and directory '/Users/jacopoferro/Documents/ADA/ada-2022-project-nan/dask-worker-space/worker-qellbot8', purging\n",
      "distributed.diskutils - INFO - Found stale lock file and directory '/Users/jacopoferro/Documents/ADA/ada-2022-project-nan/dask-worker-space/worker-h7v02y7i', purging\n",
      "distributed.diskutils - INFO - Found stale lock file and directory '/Users/jacopoferro/Documents/ADA/ada-2022-project-nan/dask-worker-space/worker-ik6kiyb_', purging\n",
      "distributed.diskutils - INFO - Found stale lock file and directory '/Users/jacopoferro/Documents/ADA/ada-2022-project-nan/dask-worker-space/worker-co_tet5h', purging\n",
      "distributed.diskutils - INFO - Found stale lock file and directory '/Users/jacopoferro/Documents/ADA/ada-2022-project-nan/dask-worker-space/worker-88ir7lm6', purging\n",
      "distributed.diskutils - INFO - Found stale lock file and directory '/Users/jacopoferro/Documents/ADA/ada-2022-project-nan/dask-worker-space/worker-f0e6qz8f', purging\n",
      "distributed.diskutils - INFO - Found stale lock file and directory '/Users/jacopoferro/Documents/ADA/ada-2022-project-nan/dask-worker-space/worker-vwfargma', purging\n",
      "distributed.diskutils - INFO - Found stale lock file and directory '/Users/jacopoferro/Documents/ADA/ada-2022-project-nan/dask-worker-space/worker-zwz3s033', purging\n",
      "distributed.diskutils - INFO - Found stale lock file and directory '/Users/jacopoferro/Documents/ADA/ada-2022-project-nan/dask-worker-space/worker-6a2l_b44', purging\n",
      "distributed.diskutils - INFO - Found stale lock file and directory '/Users/jacopoferro/Documents/ADA/ada-2022-project-nan/dask-worker-space/worker-dq6pawxt', purging\n",
      "distributed.worker - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker.html#memtrim for more information. -- Unmanaged memory: 2.48 GiB -- Worker memory limit: 3.20 GiB\n",
      "distributed.worker - WARNING - Worker is at 89% memory usage. Pausing worker.  Process memory: 2.87 GiB -- Worker memory limit: 3.20 GiB\n",
      "distributed.worker - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker.html#memtrim for more information. -- Unmanaged memory: 2.87 GiB -- Worker memory limit: 3.20 GiB\n",
      "distributed.worker - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker.html#memtrim for more information. -- Unmanaged memory: 3.15 GiB -- Worker memory limit: 3.20 GiB\n",
      "distributed.nanny - WARNING - Worker exceeded 95% memory budget. Restarting\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.worker - WARNING - Worker is at 85% memory usage. Pausing worker.  Process memory: 2.73 GiB -- Worker memory limit: 3.20 GiB\n",
      "distributed.worker - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker.html#memtrim for more information. -- Unmanaged memory: 2.73 GiB -- Worker memory limit: 3.20 GiB\n",
      "distributed.worker - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker.html#memtrim for more information. -- Unmanaged memory: 3.13 GiB -- Worker memory limit: 3.20 GiB\n",
      "distributed.nanny - WARNING - Worker exceeded 95% memory budget. Restarting\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.worker - WARNING - Worker is at 82% memory usage. Pausing worker.  Process memory: 2.64 GiB -- Worker memory limit: 3.20 GiB\n",
      "distributed.worker - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker.html#memtrim for more information. -- Unmanaged memory: 2.64 GiB -- Worker memory limit: 3.20 GiB\n",
      "distributed.worker - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker.html#memtrim for more information. -- Unmanaged memory: 3.05 GiB -- Worker memory limit: 3.20 GiB\n",
      "distributed.nanny - WARNING - Worker exceeded 95% memory budget. Restarting\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.worker - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker.html#memtrim for more information. -- Unmanaged memory: 2.26 GiB -- Worker memory limit: 3.20 GiB\n",
      "distributed.worker - WARNING - Worker is at 87% memory usage. Pausing worker.  Process memory: 2.81 GiB -- Worker memory limit: 3.20 GiB\n",
      "distributed.worker - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker.html#memtrim for more information. -- Unmanaged memory: 2.81 GiB -- Worker memory limit: 3.20 GiB\n",
      "distributed.nanny - WARNING - Worker exceeded 95% memory budget. Restarting\n",
      "distributed.nanny - WARNING - Restarting worker\n"
     ]
    },
    {
     "ename": "KilledWorker",
     "evalue": "('parse-c1a3ed1b9b8f3ff7b997c3767e86224f', <WorkerState 'tcp://127.0.0.1:58042', name: 2, status: closed, memory: 0, processing: 1>)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKilledWorker\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# load with modin\u001b[39;00m\n\u001b[1;32m      2\u001b[0m data_path \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdata/data-ssd/full/\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m df_tags \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_feather(path\u001b[39m=\u001b[39;49m data_path \u001b[39m+\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39myt_metadata_tags.feather\u001b[39;49m\u001b[39m\"\u001b[39;49m, use_threads\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/modin/logging/logger_function.py:65\u001b[0m, in \u001b[0;36mlogger_decorator.<locals>.decorator.<locals>.run_and_log\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[39mCompute function with logging if Modin logging is enabled.\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[39mAny\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mif\u001b[39;00m LogMode\u001b[39m.\u001b[39mget() \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdisable\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     67\u001b[0m logger \u001b[39m=\u001b[39m get_logger()\n\u001b[1;32m     68\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/modin/pandas/io.py:439\u001b[0m, in \u001b[0;36mread_feather\u001b[0;34m(path, columns, use_threads, storage_options)\u001b[0m\n\u001b[1;32m    436\u001b[0m Engine\u001b[39m.\u001b[39msubscribe(_update_engine)\n\u001b[1;32m    437\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmodin\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexecution\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdispatching\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfactories\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdispatcher\u001b[39;00m \u001b[39mimport\u001b[39;00m FactoryDispatcher\n\u001b[0;32m--> 439\u001b[0m \u001b[39mreturn\u001b[39;00m DataFrame(query_compiler\u001b[39m=\u001b[39mFactoryDispatcher\u001b[39m.\u001b[39;49mread_feather(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs))\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/modin/core/execution/dispatching/factories/dispatcher.py:232\u001b[0m, in \u001b[0;36mFactoryDispatcher.read_feather\u001b[0;34m(cls, **kwargs)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    230\u001b[0m \u001b[39m@_inherit_docstrings\u001b[39m(factories\u001b[39m.\u001b[39mBaseFactory\u001b[39m.\u001b[39m_read_feather)\n\u001b[1;32m    231\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mread_feather\u001b[39m(\u001b[39mcls\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 232\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m__factory\u001b[39m.\u001b[39;49m_read_feather(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/modin/core/execution/dispatching/factories/factories.py:287\u001b[0m, in \u001b[0;36mBaseFactory._read_feather\u001b[0;34m(cls, **kwargs)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    280\u001b[0m \u001b[39m@doc\u001b[39m(\n\u001b[1;32m    281\u001b[0m     _doc_io_method_template,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    285\u001b[0m )\n\u001b[1;32m    286\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_read_feather\u001b[39m(\u001b[39mcls\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 287\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mio_cls\u001b[39m.\u001b[39;49mread_feather(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/modin/logging/logger_function.py:65\u001b[0m, in \u001b[0;36mlogger_decorator.<locals>.decorator.<locals>.run_and_log\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[39mCompute function with logging if Modin logging is enabled.\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[39mAny\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mif\u001b[39;00m LogMode\u001b[39m.\u001b[39mget() \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdisable\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     67\u001b[0m logger \u001b[39m=\u001b[39m get_logger()\n\u001b[1;32m     68\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/modin/core/io/file_dispatcher.py:153\u001b[0m, in \u001b[0;36mFileDispatcher.read\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    130\u001b[0m \u001b[39m@logger_decorator\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mPANDAS-API\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mFileDispatcher.read\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mINFO\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    131\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mread\u001b[39m(\u001b[39mcls\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    132\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    133\u001b[0m \u001b[39m    Read data according passed `args` and `kwargs`.\u001b[39;00m\n\u001b[1;32m    134\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[39m    postprocessing work on the resulting query_compiler object.\u001b[39;00m\n\u001b[1;32m    152\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 153\u001b[0m     query_compiler \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_read(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    154\u001b[0m     \u001b[39m# TODO (devin-petersohn): Make this section more general for non-pandas kernel\u001b[39;00m\n\u001b[1;32m    155\u001b[0m     \u001b[39m# implementations.\u001b[39;00m\n\u001b[1;32m    156\u001b[0m     \u001b[39mif\u001b[39;00m StorageFormat\u001b[39m.\u001b[39mget() \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mPandas\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/modin/core/io/column_stores/feather_dispatcher.py:64\u001b[0m, in \u001b[0;36mFeatherDispatcher._read\u001b[0;34m(cls, path, columns, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[39m# pyarrow.feather.read_feather doesn't support columns as pandas.Index\u001b[39;00m\n\u001b[1;32m     63\u001b[0m     columns \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(df\u001b[39m.\u001b[39mcolumns)\n\u001b[0;32m---> 64\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mbuild_query_compiler(path, columns, use_threads\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/modin/core/io/column_stores/column_store_dispatcher.py:219\u001b[0m, in \u001b[0;36mColumnStoreDispatcher.build_query_compiler\u001b[0;34m(cls, path, columns, **kwargs)\u001b[0m\n\u001b[1;32m    217\u001b[0m col_partitions, column_widths \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mbuild_columns(columns)\n\u001b[1;32m    218\u001b[0m partition_ids \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mcall_deploy(path, col_partitions, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 219\u001b[0m index, row_lens \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mbuild_index(partition_ids)\n\u001b[1;32m    220\u001b[0m remote_parts \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mbuild_partition(partition_ids[:\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m], row_lens, column_widths)\n\u001b[1;32m    221\u001b[0m dtypes \u001b[39m=\u001b[39m (\n\u001b[1;32m    222\u001b[0m     \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mbuild_dtypes(partition_ids[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m], columns)\n\u001b[1;32m    223\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(partition_ids) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    224\u001b[0m     \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    225\u001b[0m )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/modin/core/io/column_stores/column_store_dispatcher.py:124\u001b[0m, in \u001b[0;36mColumnStoreDispatcher.build_index\u001b[0;34m(cls, partition_ids)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    108\u001b[0m \u001b[39mCompute index and its split sizes of resulting Modin DataFrame.\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[39m    List with lengths of index chunks.\u001b[39;00m\n\u001b[1;32m    121\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    122\u001b[0m num_partitions \u001b[39m=\u001b[39m NPartitions\u001b[39m.\u001b[39mget()\n\u001b[1;32m    123\u001b[0m index_len \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 124\u001b[0m     \u001b[39m0\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(partition_ids) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mmaterialize(partition_ids[\u001b[39m-\u001b[39;49m\u001b[39m2\u001b[39;49m][\u001b[39m0\u001b[39;49m])\n\u001b[1;32m    125\u001b[0m )\n\u001b[1;32m    126\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(index_len, \u001b[39mint\u001b[39m):\n\u001b[1;32m    127\u001b[0m     index \u001b[39m=\u001b[39m pandas\u001b[39m.\u001b[39mRangeIndex(index_len)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/modin/core/execution/dask/common/engine_wrapper.py:70\u001b[0m, in \u001b[0;36mDaskWrapper.materialize\u001b[0;34m(cls, future)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[39mMaterialize data matching `future` object.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[39m    An object(s) from the distributed memory.\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     69\u001b[0m client \u001b[39m=\u001b[39m default_client()\n\u001b[0;32m---> 70\u001b[0m \u001b[39mreturn\u001b[39;00m client\u001b[39m.\u001b[39;49mgather(future)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/distributed/client.py:1969\u001b[0m, in \u001b[0;36mClient.gather\u001b[0;34m(self, futures, errors, direct, asynchronous)\u001b[0m\n\u001b[1;32m   1967\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1968\u001b[0m     local_worker \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1969\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msync(\n\u001b[1;32m   1970\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_gather,\n\u001b[1;32m   1971\u001b[0m     futures,\n\u001b[1;32m   1972\u001b[0m     errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m   1973\u001b[0m     direct\u001b[39m=\u001b[39;49mdirect,\n\u001b[1;32m   1974\u001b[0m     local_worker\u001b[39m=\u001b[39;49mlocal_worker,\n\u001b[1;32m   1975\u001b[0m     asynchronous\u001b[39m=\u001b[39;49masynchronous,\n\u001b[1;32m   1976\u001b[0m )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/distributed/client.py:865\u001b[0m, in \u001b[0;36mClient.sync\u001b[0;34m(self, func, asynchronous, callback_timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m    863\u001b[0m     \u001b[39mreturn\u001b[39;00m future\n\u001b[1;32m    864\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 865\u001b[0m     \u001b[39mreturn\u001b[39;00m sync(\n\u001b[1;32m    866\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloop, func, \u001b[39m*\u001b[39;49margs, callback_timeout\u001b[39m=\u001b[39;49mcallback_timeout, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    867\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/distributed/utils.py:327\u001b[0m, in \u001b[0;36msync\u001b[0;34m(loop, func, callback_timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[39mif\u001b[39;00m error[\u001b[39m0\u001b[39m]:\n\u001b[1;32m    326\u001b[0m     typ, exc, tb \u001b[39m=\u001b[39m error[\u001b[39m0\u001b[39m]\n\u001b[0;32m--> 327\u001b[0m     \u001b[39mraise\u001b[39;00m exc\u001b[39m.\u001b[39mwith_traceback(tb)\n\u001b[1;32m    328\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    329\u001b[0m     \u001b[39mreturn\u001b[39;00m result[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/distributed/utils.py:310\u001b[0m, in \u001b[0;36msync.<locals>.f\u001b[0;34m()\u001b[0m\n\u001b[1;32m    308\u001b[0m     \u001b[39mif\u001b[39;00m callback_timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    309\u001b[0m         future \u001b[39m=\u001b[39m asyncio\u001b[39m.\u001b[39mwait_for(future, callback_timeout)\n\u001b[0;32m--> 310\u001b[0m     result[\u001b[39m0\u001b[39m] \u001b[39m=\u001b[39m \u001b[39myield\u001b[39;00m future\n\u001b[1;32m    311\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m    312\u001b[0m     error[\u001b[39m0\u001b[39m] \u001b[39m=\u001b[39m sys\u001b[39m.\u001b[39mexc_info()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/tornado/gen.py:769\u001b[0m, in \u001b[0;36mRunner.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    766\u001b[0m exc_info \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    768\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 769\u001b[0m     value \u001b[39m=\u001b[39m future\u001b[39m.\u001b[39;49mresult()\n\u001b[1;32m    770\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m    771\u001b[0m     exc_info \u001b[39m=\u001b[39m sys\u001b[39m.\u001b[39mexc_info()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/distributed/client.py:1834\u001b[0m, in \u001b[0;36mClient._gather\u001b[0;34m(self, futures, errors, direct, local_worker)\u001b[0m\n\u001b[1;32m   1832\u001b[0m         exc \u001b[39m=\u001b[39m CancelledError(key)\n\u001b[1;32m   1833\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1834\u001b[0m         \u001b[39mraise\u001b[39;00m exception\u001b[39m.\u001b[39mwith_traceback(traceback)\n\u001b[1;32m   1835\u001b[0m     \u001b[39mraise\u001b[39;00m exc\n\u001b[1;32m   1836\u001b[0m \u001b[39mif\u001b[39;00m errors \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mskip\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "\u001b[0;31mKilledWorker\u001b[0m: ('parse-c1a3ed1b9b8f3ff7b997c3767e86224f', <WorkerState 'tcp://127.0.0.1:58042', name: 2, status: closed, memory: 0, processing: 1>)"
     ]
    }
   ],
   "source": [
    "# load with modin\n",
    "data_path = \"data/data-ssd/full/\"\n",
    "df_tags = pd.read_feather(path= data_path + \"yt_metadata_tags.feather\", use_threads=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ray\n",
      "10\n",
      "None\n",
      "('Ray', 'Dask', 'Python', 'Native')\n",
      "MODIN_ENGINE: Distribution engine to run queries by.\n",
      "\tProvide a case-insensitive string (valid examples are: Ray, Dask, Python, Native)\n",
      "MODIN_NPARTITIONS: How many partitions to use for a Modin DataFrame (along each axis).\n",
      "\tProvide an integer value\n",
      "MODIN_RAY_CLUSTER: Whether Modin is running on pre-initialized Ray cluster.\n",
      "\tProvide a boolean flag (any of 'true', 'yes' or '1' in case insensitive manner is considered positive)\n",
      "Ray\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Ray execution environment not yet initialized. Initializing...\n",
      "To remove this warning, run the following python code before doing dataframe operations:\n",
      "\n",
      "    import ray\n",
      "    ray.init()\n",
      "\n",
      "DeprecationWarning: `ray.ray_constants.MAC_DEGRADED_PERF_MMAP_SIZE_LIMIT` is a private attribute and access will be removed in a future Ray version.\n",
      "UserWarning: On Macs, Ray's performance is known to degrade with object store size greater than 2.0 GiB. Ray by default does not allow setting an object store size greater than that. Modin is overriding that default limit because it would rather have a larger, slower object store than spill to disk more often. To override Modin's behavior, you can initialize Ray yourself.\n",
      "2022-12-12 15:24:03,661\tINFO worker.py:1528 -- Started a local Ray instance.\n",
      "2022-12-12 15:24:04,437\tWARNING __init__.py:191 -- DeprecationWarning: `ray.worker.global_worker` is a private attribute and access will be removed in a future Ray version.\n"
     ]
    }
   ],
   "source": [
    "# I'll leave the output here for reference, lets try again\n",
    "# let's try to explicitely use dask or ray\n",
    "import modin.pandas as pd\n",
    "import modin\n",
    "print(modin.config.Engine.get())\n",
    "print(modin.config.NPartitions.get())\n",
    "print(modin.config.IsRayCluster.get())\n",
    "print(modin.config.Engine.choices)\n",
    "print(modin.config.Engine.get_help())\n",
    "print(modin.config.NPartitions.get_help())\n",
    "print(modin.config.IsRayCluster.get_help())\n",
    "# https://github.com/modin-project/modin/pull/292#issuecomment-445915511 mmmh...\n",
    "modin.config.Engine.put('Ray') # had to install ray from pip, not present in conda\n",
    "print(modin.config.Engine.get())\n",
    "data_path = \"data/data-ssd/full/\"\n",
    "import timeit\n",
    "start = timeit.default_timer()\n",
    "df_tags = pd.read_feather(path= data_path + \"yt_metadata_tags.feather\", use_threads=True)\n",
    "stop = timeit.default_timer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  304.4392979169497\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lego city,lego police,lego city police,lego ci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lego superheroes,lego hulk,hulk smash,lego mar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lego city,lego police,lego city police,lego fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lego harry potter,new harry potter,harry potte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lego city,lego police,lego city police,lego fi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                tags\n",
       "0  lego city,lego police,lego city police,lego ci...\n",
       "1  Lego superheroes,lego hulk,hulk smash,lego mar...\n",
       "2  lego city,lego police,lego city police,lego fi...\n",
       "3  Lego harry potter,new harry potter,harry potte...\n",
       "4  lego city,lego police,lego city police,lego fi..."
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Time: ', stop - start)\n",
    "df_tags.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(raylet)\u001b[0m Spilled 2216 MiB, 2 objects, write throughput 240 MiB/s. Set RAY_verbose_spill_logs=0 to disable this message.\n",
      "\u001b[2m\u001b[36m(raylet)\u001b[0m Spilled 4375 MiB, 4 objects, write throughput 339 MiB/s.\n",
      "\u001b[2m\u001b[36m(raylet)\u001b[0m Spilled 18756 MiB, 17 objects, write throughput 663 MiB/s.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  436.12635588645935\n",
      "1670855744.754067\n",
      "1670856180.8804228\n"
     ]
    }
   ],
   "source": [
    "# let's run it again now that ray is installed and initialized\n",
    "import time\n",
    "start = time.time()\n",
    "df_tags = pd.read_feather(path= data_path + \"yt_metadata_tags.feather\", use_threads=True)\n",
    "stop = time.time()\n",
    "print('Time: ', stop - start)\n",
    "print(start)\n",
    "print(stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Distributing <class 'int'> object. This may take some time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'modin.pandas.dataframe.DataFrame'>\n",
      "RangeIndex: 72924794 entries, 0 to 72924793\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count     Dtype \n",
      "---  ------  -----------------  ----- \n",
      " 0   tags    72924794 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 556.4 MB\n"
     ]
    }
   ],
   "source": [
    "# I just realized the bottleneck is the ssd at this point, not the cpu or pandas or ray!\n",
    "# Now that is in memory tho it should be faster than pandas. Splitting the tags took 30min and didn't even finish, let's try again here\n",
    "df_tags.info() # what.. took 50s...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  0.844296932220459\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "df_tags = df_tags['tags'].apply(lambda x: x.split(\",\"))\n",
    "stop = time.time()\n",
    "print('Time: ', stop - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [38], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# WHAT????? Did it actually work?\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df_tags\u001b[39m.\u001b[39mhead()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/IPython/core/displayhook.py:262\u001b[0m, in \u001b[0;36mDisplayHook.__call__\u001b[0;34m(self, result)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstart_displayhook()\n\u001b[1;32m    261\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrite_output_prompt()\n\u001b[0;32m--> 262\u001b[0m format_dict, md_dict \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_format_data(result)\n\u001b[1;32m    263\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mupdate_user_ns(result)\n\u001b[1;32m    264\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfill_exec_result(result)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/IPython/core/displayhook.py:151\u001b[0m, in \u001b[0;36mDisplayHook.compute_format_data\u001b[0;34m(self, result)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompute_format_data\u001b[39m(\u001b[39mself\u001b[39m, result):\n\u001b[1;32m    122\u001b[0m     \u001b[39m\"\"\"Compute format data of the object to be displayed.\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \n\u001b[1;32m    124\u001b[0m \u001b[39m    The format data is a generalization of the :func:`repr` of an object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    149\u001b[0m \n\u001b[1;32m    150\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 151\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mshell\u001b[39m.\u001b[39;49mdisplay_formatter\u001b[39m.\u001b[39;49mformat(result)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/IPython/core/formatters.py:177\u001b[0m, in \u001b[0;36mDisplayFormatter.format\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    175\u001b[0m md \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    176\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 177\u001b[0m     data \u001b[39m=\u001b[39m formatter(obj)\n\u001b[1;32m    178\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m    179\u001b[0m     \u001b[39m# FIXME: log the exception\u001b[39;00m\n\u001b[1;32m    180\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/decorator.py:232\u001b[0m, in \u001b[0;36mdecorate.<locals>.fun\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m kwsyntax:\n\u001b[1;32m    231\u001b[0m     args, kw \u001b[39m=\u001b[39m fix(args, kw, sig)\n\u001b[0;32m--> 232\u001b[0m \u001b[39mreturn\u001b[39;00m caller(func, \u001b[39m*\u001b[39;49m(extras \u001b[39m+\u001b[39;49m args), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/IPython/core/formatters.py:221\u001b[0m, in \u001b[0;36mcatch_format_error\u001b[0;34m(method, self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[39m\"\"\"show traceback on failed format call\"\"\"\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 221\u001b[0m     r \u001b[39m=\u001b[39m method(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    222\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m:\n\u001b[1;32m    223\u001b[0m     \u001b[39m# don't warn on NotImplementedErrors\u001b[39;00m\n\u001b[1;32m    224\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_return(\u001b[39mNone\u001b[39;00m, args[\u001b[39m0\u001b[39m])\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/IPython/core/formatters.py:706\u001b[0m, in \u001b[0;36mPlainTextFormatter.__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    699\u001b[0m stream \u001b[39m=\u001b[39m StringIO()\n\u001b[1;32m    700\u001b[0m printer \u001b[39m=\u001b[39m pretty\u001b[39m.\u001b[39mRepresentationPrinter(stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose,\n\u001b[1;32m    701\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_width, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnewline,\n\u001b[1;32m    702\u001b[0m     max_seq_length\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_seq_length,\n\u001b[1;32m    703\u001b[0m     singleton_pprinters\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msingleton_printers,\n\u001b[1;32m    704\u001b[0m     type_pprinters\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtype_printers,\n\u001b[1;32m    705\u001b[0m     deferred_pprinters\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdeferred_printers)\n\u001b[0;32m--> 706\u001b[0m printer\u001b[39m.\u001b[39;49mpretty(obj)\n\u001b[1;32m    707\u001b[0m printer\u001b[39m.\u001b[39mflush()\n\u001b[1;32m    708\u001b[0m \u001b[39mreturn\u001b[39;00m stream\u001b[39m.\u001b[39mgetvalue()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/IPython/lib/pretty.py:410\u001b[0m, in \u001b[0;36mRepresentationPrinter.pretty\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    407\u001b[0m                         \u001b[39mreturn\u001b[39;00m meth(obj, \u001b[39mself\u001b[39m, cycle)\n\u001b[1;32m    408\u001b[0m                 \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mobject\u001b[39m \\\n\u001b[1;32m    409\u001b[0m                         \u001b[39mand\u001b[39;00m callable(\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__dict__\u001b[39m\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39m__repr__\u001b[39m\u001b[39m'\u001b[39m)):\n\u001b[0;32m--> 410\u001b[0m                     \u001b[39mreturn\u001b[39;00m _repr_pprint(obj, \u001b[39mself\u001b[39;49m, cycle)\n\u001b[1;32m    412\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_pprint(obj, \u001b[39mself\u001b[39m, cycle)\n\u001b[1;32m    413\u001b[0m \u001b[39mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/IPython/lib/pretty.py:778\u001b[0m, in \u001b[0;36m_repr_pprint\u001b[0;34m(obj, p, cycle)\u001b[0m\n\u001b[1;32m    776\u001b[0m \u001b[39m\"\"\"A pprint that just redirects to the normal repr function.\"\"\"\u001b[39;00m\n\u001b[1;32m    777\u001b[0m \u001b[39m# Find newlines and replace them with p.break_()\u001b[39;00m\n\u001b[0;32m--> 778\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mrepr\u001b[39;49m(obj)\n\u001b[1;32m    779\u001b[0m lines \u001b[39m=\u001b[39m output\u001b[39m.\u001b[39msplitlines()\n\u001b[1;32m    780\u001b[0m \u001b[39mwith\u001b[39;00m p\u001b[39m.\u001b[39mgroup():\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/modin/logging/logger_metaclass.py:68\u001b[0m, in \u001b[0;36mlogger_class_wrapper.<locals>.log_wrap\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     66\u001b[0m     logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEND::PANDAS-API::\u001b[39m\u001b[39m{\u001b[39;00mclass_name\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mmethod_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     67\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n\u001b[0;32m---> 68\u001b[0m \u001b[39mreturn\u001b[39;00m method(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/modin/pandas/series.py:419\u001b[0m, in \u001b[0;36mSeries.__repr__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    417\u001b[0m num_rows \u001b[39m=\u001b[39m pandas\u001b[39m.\u001b[39mget_option(\u001b[39m\"\u001b[39m\u001b[39mdisplay.max_rows\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mor\u001b[39;00m \u001b[39m60\u001b[39m\n\u001b[1;32m    418\u001b[0m num_cols \u001b[39m=\u001b[39m pandas\u001b[39m.\u001b[39mget_option(\u001b[39m\"\u001b[39m\u001b[39mdisplay.max_columns\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mor\u001b[39;00m \u001b[39m20\u001b[39m\n\u001b[0;32m--> 419\u001b[0m temp_df \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_build_repr_df(num_rows, num_cols)\n\u001b[1;32m    420\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(temp_df, pandas\u001b[39m.\u001b[39mDataFrame) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m temp_df\u001b[39m.\u001b[39mempty:\n\u001b[1;32m    421\u001b[0m     temp_df \u001b[39m=\u001b[39m temp_df\u001b[39m.\u001b[39miloc[:, \u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/modin/logging/logger_metaclass.py:68\u001b[0m, in \u001b[0;36mlogger_class_wrapper.<locals>.log_wrap\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     66\u001b[0m     logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEND::PANDAS-API::\u001b[39m\u001b[39m{\u001b[39;00mclass_name\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mmethod_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     67\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n\u001b[0;32m---> 68\u001b[0m \u001b[39mreturn\u001b[39;00m method(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/modin/pandas/base.py:203\u001b[0m, in \u001b[0;36mBasePandasDataset._build_repr_df\u001b[0;34m(self, num_rows, num_cols)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     indexer \u001b[39m=\u001b[39m row_indexer\n\u001b[0;32m--> 203\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miloc[indexer]\u001b[39m.\u001b[39;49m_query_compiler\u001b[39m.\u001b[39;49mto_pandas()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/modin/logging/logger_metaclass.py:68\u001b[0m, in \u001b[0;36mlogger_class_wrapper.<locals>.log_wrap\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     66\u001b[0m     logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEND::PANDAS-API::\u001b[39m\u001b[39m{\u001b[39;00mclass_name\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mmethod_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     67\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n\u001b[0;32m---> 68\u001b[0m \u001b[39mreturn\u001b[39;00m method(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/modin/core/storage_formats/pandas/query_compiler.py:259\u001b[0m, in \u001b[0;36mPandasQueryCompiler.to_pandas\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mto_pandas\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 259\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_modin_frame\u001b[39m.\u001b[39;49mto_pandas()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/modin/logging/logger_metaclass.py:68\u001b[0m, in \u001b[0;36mlogger_class_wrapper.<locals>.log_wrap\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     66\u001b[0m     logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEND::PANDAS-API::\u001b[39m\u001b[39m{\u001b[39;00mclass_name\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mmethod_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     67\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n\u001b[0;32m---> 68\u001b[0m \u001b[39mreturn\u001b[39;00m method(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/modin/core/dataframe/pandas/dataframe/dataframe.py:115\u001b[0m, in \u001b[0;36mlazy_metadata_decorator.<locals>.decorator.<locals>.run_f_on_minimally_updated_metadata\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[39melif\u001b[39;00m apply_axis \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrows\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    114\u001b[0m         obj\u001b[39m.\u001b[39m_propagate_index_objs(axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m--> 115\u001b[0m result \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    116\u001b[0m \u001b[39mif\u001b[39;00m apply_axis \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m transpose:\n\u001b[1;32m    117\u001b[0m     result\u001b[39m.\u001b[39m_deferred_index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_deferred_index\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/modin/core/dataframe/pandas/dataframe/dataframe.py:2835\u001b[0m, in \u001b[0;36mPandasDataframe.to_pandas\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2826\u001b[0m \u001b[39m@lazy_metadata_decorator\u001b[39m(apply_axis\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mboth\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   2827\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mto_pandas\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m   2828\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2829\u001b[0m \u001b[39m    Convert this Modin DataFrame to a pandas DataFrame.\u001b[39;00m\n\u001b[1;32m   2830\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2833\u001b[0m \u001b[39m    pandas.DataFrame\u001b[39;00m\n\u001b[1;32m   2834\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2835\u001b[0m     df \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_partition_mgr_cls\u001b[39m.\u001b[39;49mto_pandas(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_partitions)\n\u001b[1;32m   2836\u001b[0m     \u001b[39mif\u001b[39;00m df\u001b[39m.\u001b[39mempty:\n\u001b[1;32m   2837\u001b[0m         df \u001b[39m=\u001b[39m pandas\u001b[39m.\u001b[39mDataFrame(columns\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns, index\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/modin/core/dataframe/pandas/partitioning/partition_manager.py:639\u001b[0m, in \u001b[0;36mPandasDataframePartitionManager.to_pandas\u001b[0;34m(cls, partitions)\u001b[0m\n\u001b[1;32m    624\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    625\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mto_pandas\u001b[39m(\u001b[39mcls\u001b[39m, partitions):\n\u001b[1;32m    626\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    627\u001b[0m \u001b[39m    Convert NumPy array of PandasDataframePartition to pandas DataFrame.\u001b[39;00m\n\u001b[1;32m    628\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    637\u001b[0m \u001b[39m        A pandas DataFrame\u001b[39;00m\n\u001b[1;32m    638\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 639\u001b[0m     retrieved_objects \u001b[39m=\u001b[39m [[obj\u001b[39m.\u001b[39mto_pandas() \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m part] \u001b[39mfor\u001b[39;00m part \u001b[39min\u001b[39;00m partitions]\n\u001b[1;32m    640\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mall\u001b[39m(\n\u001b[1;32m    641\u001b[0m         \u001b[39misinstance\u001b[39m(part, pandas\u001b[39m.\u001b[39mSeries) \u001b[39mfor\u001b[39;00m row \u001b[39min\u001b[39;00m retrieved_objects \u001b[39mfor\u001b[39;00m part \u001b[39min\u001b[39;00m row\n\u001b[1;32m    642\u001b[0m     ):\n\u001b[1;32m    643\u001b[0m         axis \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/modin/core/dataframe/pandas/partitioning/partition_manager.py:639\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    624\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    625\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mto_pandas\u001b[39m(\u001b[39mcls\u001b[39m, partitions):\n\u001b[1;32m    626\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    627\u001b[0m \u001b[39m    Convert NumPy array of PandasDataframePartition to pandas DataFrame.\u001b[39;00m\n\u001b[1;32m    628\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    637\u001b[0m \u001b[39m        A pandas DataFrame\u001b[39;00m\n\u001b[1;32m    638\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 639\u001b[0m     retrieved_objects \u001b[39m=\u001b[39m [[obj\u001b[39m.\u001b[39mto_pandas() \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m part] \u001b[39mfor\u001b[39;00m part \u001b[39min\u001b[39;00m partitions]\n\u001b[1;32m    640\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mall\u001b[39m(\n\u001b[1;32m    641\u001b[0m         \u001b[39misinstance\u001b[39m(part, pandas\u001b[39m.\u001b[39mSeries) \u001b[39mfor\u001b[39;00m row \u001b[39min\u001b[39;00m retrieved_objects \u001b[39mfor\u001b[39;00m part \u001b[39min\u001b[39;00m row\n\u001b[1;32m    642\u001b[0m     ):\n\u001b[1;32m    643\u001b[0m         axis \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/modin/core/dataframe/pandas/partitioning/partition_manager.py:639\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    624\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    625\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mto_pandas\u001b[39m(\u001b[39mcls\u001b[39m, partitions):\n\u001b[1;32m    626\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    627\u001b[0m \u001b[39m    Convert NumPy array of PandasDataframePartition to pandas DataFrame.\u001b[39;00m\n\u001b[1;32m    628\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    637\u001b[0m \u001b[39m        A pandas DataFrame\u001b[39;00m\n\u001b[1;32m    638\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 639\u001b[0m     retrieved_objects \u001b[39m=\u001b[39m [[obj\u001b[39m.\u001b[39;49mto_pandas() \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m part] \u001b[39mfor\u001b[39;00m part \u001b[39min\u001b[39;00m partitions]\n\u001b[1;32m    640\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mall\u001b[39m(\n\u001b[1;32m    641\u001b[0m         \u001b[39misinstance\u001b[39m(part, pandas\u001b[39m.\u001b[39mSeries) \u001b[39mfor\u001b[39;00m row \u001b[39min\u001b[39;00m retrieved_objects \u001b[39mfor\u001b[39;00m part \u001b[39min\u001b[39;00m row\n\u001b[1;32m    642\u001b[0m     ):\n\u001b[1;32m    643\u001b[0m         axis \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/modin/core/dataframe/pandas/partitioning/partition.py:125\u001b[0m, in \u001b[0;36mPandasDataframePartition.to_pandas\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mto_pandas\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    113\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[39m    Convert the object wrapped by this partition to a ``pandas.DataFrame``.\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[39m    only need to call `get`.\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 125\u001b[0m     dataframe \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget()\n\u001b[1;32m    126\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(dataframe, (pandas\u001b[39m.\u001b[39mDataFrame, pandas\u001b[39m.\u001b[39mSeries))\n\u001b[1;32m    127\u001b[0m     \u001b[39mreturn\u001b[39;00m dataframe\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/modin/core/execution/ray/implementations/pandas_on_ray/partitioning/partition.py:80\u001b[0m, in \u001b[0;36mPandasOnRayDataframePartition.get\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcall_queue):\n\u001b[1;32m     79\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdrain_call_queue()\n\u001b[0;32m---> 80\u001b[0m result \u001b[39m=\u001b[39m ray\u001b[39m.\u001b[39;49mget(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moid)\n\u001b[1;32m     81\u001b[0m logger\u001b[39m.\u001b[39mdebug(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEXIT::Partition.get::\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_identity\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     82\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/ray/_private/client_mode_hook.py:105\u001b[0m, in \u001b[0;36mclient_mode_hook.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[39mif\u001b[39;00m func\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39minit\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m is_client_mode_enabled_by_default:\n\u001b[1;32m    104\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39m(ray, func\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 105\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/ray/_private/worker.py:2283\u001b[0m, in \u001b[0;36mget\u001b[0;34m(object_refs, timeout)\u001b[0m\n\u001b[1;32m   2278\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   2279\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mobject_refs\u001b[39m\u001b[39m'\u001b[39m\u001b[39m must either be an ObjectRef or a list of ObjectRefs.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2280\u001b[0m     )\n\u001b[1;32m   2282\u001b[0m \u001b[39m# TODO(ujvl): Consider how to allow user to retrieve the ready objects.\u001b[39;00m\n\u001b[0;32m-> 2283\u001b[0m values, debugger_breakpoint \u001b[39m=\u001b[39m worker\u001b[39m.\u001b[39;49mget_objects(object_refs, timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m   2284\u001b[0m \u001b[39mfor\u001b[39;00m i, value \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(values):\n\u001b[1;32m   2285\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(value, RayError):\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/ray/_private/worker.py:668\u001b[0m, in \u001b[0;36mWorker.get_objects\u001b[0;34m(self, object_refs, timeout)\u001b[0m\n\u001b[1;32m    662\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m    663\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mAttempting to call `get` on the value \u001b[39m\u001b[39m{\u001b[39;00mobject_ref\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    664\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mwhich is not an ray.ObjectRef.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    665\u001b[0m         )\n\u001b[1;32m    667\u001b[0m timeout_ms \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(timeout \u001b[39m*\u001b[39m \u001b[39m1000\u001b[39m) \u001b[39mif\u001b[39;00m timeout \u001b[39melse\u001b[39;00m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m--> 668\u001b[0m data_metadata_pairs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcore_worker\u001b[39m.\u001b[39;49mget_objects(\n\u001b[1;32m    669\u001b[0m     object_refs, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcurrent_task_id, timeout_ms\n\u001b[1;32m    670\u001b[0m )\n\u001b[1;32m    671\u001b[0m debugger_breakpoint \u001b[39m=\u001b[39m \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    672\u001b[0m \u001b[39mfor\u001b[39;00m (data, metadata) \u001b[39min\u001b[39;00m data_metadata_pairs:\n",
      "File \u001b[0;32mpython/ray/_raylet.pyx:1445\u001b[0m, in \u001b[0;36mray._raylet.CoreWorker.get_objects\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpython/ray/_raylet.pyx:190\u001b[0m, in \u001b[0;36mray._raylet.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# WHAT????? Did it actually work?\n",
    "df_tags.head() # head() takes more time than apply, \n",
    "#clearly some operations are super  optimized while others require to aggregate the whole dataset in a single node and are suuuuuuper slow\n",
    "# 5min and it actually didn't finish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  59.37336993217468\n"
     ]
    }
   ],
   "source": [
    "# I will copy the feather tags file to my disk and try again\n",
    "data_path = \"data/full/\"\n",
    "import time\n",
    "start = time.time()\n",
    "df_tags = pd.read_feather(path= data_path + \"yt_metadata_tags.feather\", use_threads=True)\n",
    "stop = time.time()\n",
    "print('Time: ', stop - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 72924794 entries, 0 to 72924793\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Dtype \n",
      "---  ------  ----- \n",
      " 0   tags    object\n",
      "dtypes: object(1)\n",
      "memory usage: 556.4+ MB\n",
      "None\n",
      "Time:  0.05313467979431152\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(df_tags.info())\n",
    "stop = time.time()\n",
    "print('Time: ', stop - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                tags\n",
      "0  lego city,lego police,lego city police,lego ci...\n",
      "1  Lego superheroes,lego hulk,hulk smash,lego mar...\n",
      "2  lego city,lego police,lego city police,lego fi...\n",
      "3  Lego harry potter,new harry potter,harry potte...\n",
      "4  lego city,lego police,lego city police,lego fi...\n",
      "Time:  0.01375579833984375\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(df_tags.head())\n",
    "stop = time.time()\n",
    "print('Time: ', stop - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m----> 2\u001b[0m df_tags \u001b[39m=\u001b[39m df_tags[\u001b[39m'\u001b[39;49m\u001b[39mtags\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mapply(\u001b[39mlambda\u001b[39;49;00m x: x\u001b[39m.\u001b[39;49msplit(\u001b[39m\"\u001b[39;49m\u001b[39m,\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n\u001b[1;32m      3\u001b[0m \u001b[39mprint\u001b[39m(df_tags\u001b[39m.\u001b[39mhead())\n\u001b[1;32m      4\u001b[0m stop \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/pandas/core/series.py:4433\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4323\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[1;32m   4324\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   4325\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4328\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   4329\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[1;32m   4330\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   4331\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4332\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4431\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4432\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4433\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\u001b[39mself\u001b[39;49m, func, convert_dtype, args, kwargs)\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/pandas/core/apply.py:1088\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1084\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf, \u001b[39mstr\u001b[39m):\n\u001b[1;32m   1085\u001b[0m     \u001b[39m# if we are a string, try to dispatch\u001b[39;00m\n\u001b[1;32m   1086\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[0;32m-> 1088\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/pandas/core/apply.py:1143\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1137\u001b[0m         values \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m)\u001b[39m.\u001b[39m_values\n\u001b[1;32m   1138\u001b[0m         \u001b[39m# error: Argument 2 to \"map_infer\" has incompatible type\u001b[39;00m\n\u001b[1;32m   1139\u001b[0m         \u001b[39m# \"Union[Callable[..., Any], str, List[Union[Callable[..., Any], str]],\u001b[39;00m\n\u001b[1;32m   1140\u001b[0m         \u001b[39m# Dict[Hashable, Union[Union[Callable[..., Any], str],\u001b[39;00m\n\u001b[1;32m   1141\u001b[0m         \u001b[39m# List[Union[Callable[..., Any], str]]]]]\"; expected\u001b[39;00m\n\u001b[1;32m   1142\u001b[0m         \u001b[39m# \"Callable[[Any], Any]\"\u001b[39;00m\n\u001b[0;32m-> 1143\u001b[0m         mapped \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mmap_infer(\n\u001b[1;32m   1144\u001b[0m             values,\n\u001b[1;32m   1145\u001b[0m             f,  \u001b[39m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1146\u001b[0m             convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype,\n\u001b[1;32m   1147\u001b[0m         )\n\u001b[1;32m   1149\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1150\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1151\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1152\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/pandas/_libs/lib.pyx:2870\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn [8], line 2\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m----> 2\u001b[0m df_tags \u001b[39m=\u001b[39m df_tags[\u001b[39m'\u001b[39m\u001b[39mtags\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: x\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m      3\u001b[0m \u001b[39mprint\u001b[39m(df_tags\u001b[39m.\u001b[39mhead())\n\u001b[1;32m      4\u001b[0m stop \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "df_tags = df_tags['tags'].apply(lambda x: x.split(\",\"))\n",
    "print(df_tags.head())\n",
    "stop = time.time()\n",
    "print('Time: ', stop - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Dask execution environment not yet initialized. Initializing...\n",
      "To remove this warning, run the following python code before doing dataframe operations:\n",
      "\n",
      "    from distributed import Client\n",
      "\n",
      "    client = Client()\n",
      "\n",
      "distributed.diskutils - INFO - Found stale lock file and directory '/Users/jacopoferro/Documents/ADA/ada-2022-project-nan/dask-worker-space/worker-6g0a94de', purging\n",
      "distributed.diskutils - INFO - Found stale lock file and directory '/Users/jacopoferro/Documents/ADA/ada-2022-project-nan/dask-worker-space/worker-2xc3dfbb', purging\n",
      "distributed.diskutils - INFO - Found stale lock file and directory '/Users/jacopoferro/Documents/ADA/ada-2022-project-nan/dask-worker-space/worker-xrgty7r_', purging\n",
      "distributed.diskutils - INFO - Found stale lock file and directory '/Users/jacopoferro/Documents/ADA/ada-2022-project-nan/dask-worker-space/worker-jmyht63b', purging\n",
      "distributed.diskutils - INFO - Found stale lock file and directory '/Users/jacopoferro/Documents/ADA/ada-2022-project-nan/dask-worker-space/worker-nnc9u29l', purging\n",
      "distributed.diskutils - INFO - Found stale lock file and directory '/Users/jacopoferro/Documents/ADA/ada-2022-project-nan/dask-worker-space/worker-n7p6y62p', purging\n",
      "distributed.diskutils - INFO - Found stale lock file and directory '/Users/jacopoferro/Documents/ADA/ada-2022-project-nan/dask-worker-space/worker-vbtmafcx', purging\n",
      "distributed.diskutils - INFO - Found stale lock file and directory '/Users/jacopoferro/Documents/ADA/ada-2022-project-nan/dask-worker-space/worker-55lhxume', purging\n",
      "distributed.diskutils - INFO - Found stale lock file and directory '/Users/jacopoferro/Documents/ADA/ada-2022-project-nan/dask-worker-space/worker-c5dqeijg', purging\n",
      "distributed.diskutils - INFO - Found stale lock file and directory '/Users/jacopoferro/Documents/ADA/ada-2022-project-nan/dask-worker-space/worker-31iythxz', purging\n",
      "distributed.worker - WARNING - Worker is at 82% memory usage. Pausing worker.  Process memory: 2.64 GiB -- Worker memory limit: 3.20 GiB\n",
      "distributed.worker - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker.html#memtrim for more information. -- Unmanaged memory: 2.64 GiB -- Worker memory limit: 3.20 GiB\n",
      "distributed.worker - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker.html#memtrim for more information. -- Unmanaged memory: 3.09 GiB -- Worker memory limit: 3.20 GiB\n",
      "distributed.nanny - WARNING - Worker exceeded 95% memory budget. Restarting\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.worker - WARNING - Worker is at 87% memory usage. Pausing worker.  Process memory: 2.79 GiB -- Worker memory limit: 3.20 GiB\n",
      "distributed.worker - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker.html#memtrim for more information. -- Unmanaged memory: 2.79 GiB -- Worker memory limit: 3.20 GiB\n",
      "distributed.worker - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker.html#memtrim for more information. -- Unmanaged memory: 3.18 GiB -- Worker memory limit: 3.20 GiB\n",
      "distributed.nanny - WARNING - Worker exceeded 95% memory budget. Restarting\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.worker - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker.html#memtrim for more information. -- Unmanaged memory: 2.30 GiB -- Worker memory limit: 3.20 GiB\n",
      "distributed.worker - WARNING - Worker is at 88% memory usage. Pausing worker.  Process memory: 2.85 GiB -- Worker memory limit: 3.20 GiB\n",
      "distributed.worker - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker.html#memtrim for more information. -- Unmanaged memory: 2.85 GiB -- Worker memory limit: 3.20 GiB\n",
      "distributed.nanny - WARNING - Worker exceeded 95% memory budget. Restarting\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.worker - WARNING - Worker is at 81% memory usage. Pausing worker.  Process memory: 2.60 GiB -- Worker memory limit: 3.20 GiB\n",
      "distributed.worker - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker.html#memtrim for more information. -- Unmanaged memory: 2.60 GiB -- Worker memory limit: 3.20 GiB\n",
      "distributed.worker - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker.html#memtrim for more information. -- Unmanaged memory: 3.05 GiB -- Worker memory limit: 3.20 GiB\n",
      "distributed.nanny - WARNING - Worker exceeded 95% memory budget. Restarting\n",
      "distributed.nanny - WARNING - Restarting worker\n"
     ]
    },
    {
     "ename": "KilledWorker",
     "evalue": "('parse-d6e9b0b42113e9ec9cc94cf6a479de0b', <WorkerState 'tcp://127.0.0.1:55891', name: 8, status: closed, memory: 0, processing: 1>)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKilledWorker\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtime\u001b[39;00m\n\u001b[1;32m     15\u001b[0m start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m---> 16\u001b[0m df_tags \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_feather(path\u001b[39m=\u001b[39;49m data_path \u001b[39m+\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39myt_metadata_tags.feather\u001b[39;49m\u001b[39m\"\u001b[39;49m, use_threads\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     17\u001b[0m stop \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m     18\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mTime: \u001b[39m\u001b[39m'\u001b[39m, stop \u001b[39m-\u001b[39m start)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/modin/logging/logger_function.py:65\u001b[0m, in \u001b[0;36mlogger_decorator.<locals>.decorator.<locals>.run_and_log\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[39mCompute function with logging if Modin logging is enabled.\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[39mAny\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mif\u001b[39;00m LogMode\u001b[39m.\u001b[39mget() \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdisable\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     67\u001b[0m logger \u001b[39m=\u001b[39m get_logger()\n\u001b[1;32m     68\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/modin/pandas/io.py:439\u001b[0m, in \u001b[0;36mread_feather\u001b[0;34m(path, columns, use_threads, storage_options)\u001b[0m\n\u001b[1;32m    436\u001b[0m Engine\u001b[39m.\u001b[39msubscribe(_update_engine)\n\u001b[1;32m    437\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmodin\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexecution\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdispatching\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfactories\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdispatcher\u001b[39;00m \u001b[39mimport\u001b[39;00m FactoryDispatcher\n\u001b[0;32m--> 439\u001b[0m \u001b[39mreturn\u001b[39;00m DataFrame(query_compiler\u001b[39m=\u001b[39mFactoryDispatcher\u001b[39m.\u001b[39;49mread_feather(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs))\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/modin/core/execution/dispatching/factories/dispatcher.py:232\u001b[0m, in \u001b[0;36mFactoryDispatcher.read_feather\u001b[0;34m(cls, **kwargs)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    230\u001b[0m \u001b[39m@_inherit_docstrings\u001b[39m(factories\u001b[39m.\u001b[39mBaseFactory\u001b[39m.\u001b[39m_read_feather)\n\u001b[1;32m    231\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mread_feather\u001b[39m(\u001b[39mcls\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 232\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m__factory\u001b[39m.\u001b[39;49m_read_feather(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/modin/core/execution/dispatching/factories/factories.py:287\u001b[0m, in \u001b[0;36mBaseFactory._read_feather\u001b[0;34m(cls, **kwargs)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    280\u001b[0m \u001b[39m@doc\u001b[39m(\n\u001b[1;32m    281\u001b[0m     _doc_io_method_template,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    285\u001b[0m )\n\u001b[1;32m    286\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_read_feather\u001b[39m(\u001b[39mcls\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 287\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mio_cls\u001b[39m.\u001b[39;49mread_feather(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/modin/logging/logger_function.py:65\u001b[0m, in \u001b[0;36mlogger_decorator.<locals>.decorator.<locals>.run_and_log\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[39mCompute function with logging if Modin logging is enabled.\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[39mAny\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mif\u001b[39;00m LogMode\u001b[39m.\u001b[39mget() \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdisable\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     67\u001b[0m logger \u001b[39m=\u001b[39m get_logger()\n\u001b[1;32m     68\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/modin/core/io/file_dispatcher.py:153\u001b[0m, in \u001b[0;36mFileDispatcher.read\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    130\u001b[0m \u001b[39m@logger_decorator\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mPANDAS-API\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mFileDispatcher.read\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mINFO\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    131\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mread\u001b[39m(\u001b[39mcls\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    132\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    133\u001b[0m \u001b[39m    Read data according passed `args` and `kwargs`.\u001b[39;00m\n\u001b[1;32m    134\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[39m    postprocessing work on the resulting query_compiler object.\u001b[39;00m\n\u001b[1;32m    152\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 153\u001b[0m     query_compiler \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_read(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    154\u001b[0m     \u001b[39m# TODO (devin-petersohn): Make this section more general for non-pandas kernel\u001b[39;00m\n\u001b[1;32m    155\u001b[0m     \u001b[39m# implementations.\u001b[39;00m\n\u001b[1;32m    156\u001b[0m     \u001b[39mif\u001b[39;00m StorageFormat\u001b[39m.\u001b[39mget() \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mPandas\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/modin/core/io/column_stores/feather_dispatcher.py:64\u001b[0m, in \u001b[0;36mFeatherDispatcher._read\u001b[0;34m(cls, path, columns, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[39m# pyarrow.feather.read_feather doesn't support columns as pandas.Index\u001b[39;00m\n\u001b[1;32m     63\u001b[0m     columns \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(df\u001b[39m.\u001b[39mcolumns)\n\u001b[0;32m---> 64\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mbuild_query_compiler(path, columns, use_threads\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/modin/core/io/column_stores/column_store_dispatcher.py:219\u001b[0m, in \u001b[0;36mColumnStoreDispatcher.build_query_compiler\u001b[0;34m(cls, path, columns, **kwargs)\u001b[0m\n\u001b[1;32m    217\u001b[0m col_partitions, column_widths \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mbuild_columns(columns)\n\u001b[1;32m    218\u001b[0m partition_ids \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mcall_deploy(path, col_partitions, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 219\u001b[0m index, row_lens \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mbuild_index(partition_ids)\n\u001b[1;32m    220\u001b[0m remote_parts \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mbuild_partition(partition_ids[:\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m], row_lens, column_widths)\n\u001b[1;32m    221\u001b[0m dtypes \u001b[39m=\u001b[39m (\n\u001b[1;32m    222\u001b[0m     \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mbuild_dtypes(partition_ids[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m], columns)\n\u001b[1;32m    223\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(partition_ids) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    224\u001b[0m     \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    225\u001b[0m )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/modin/core/io/column_stores/column_store_dispatcher.py:124\u001b[0m, in \u001b[0;36mColumnStoreDispatcher.build_index\u001b[0;34m(cls, partition_ids)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    108\u001b[0m \u001b[39mCompute index and its split sizes of resulting Modin DataFrame.\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[39m    List with lengths of index chunks.\u001b[39;00m\n\u001b[1;32m    121\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    122\u001b[0m num_partitions \u001b[39m=\u001b[39m NPartitions\u001b[39m.\u001b[39mget()\n\u001b[1;32m    123\u001b[0m index_len \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 124\u001b[0m     \u001b[39m0\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(partition_ids) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mmaterialize(partition_ids[\u001b[39m-\u001b[39;49m\u001b[39m2\u001b[39;49m][\u001b[39m0\u001b[39;49m])\n\u001b[1;32m    125\u001b[0m )\n\u001b[1;32m    126\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(index_len, \u001b[39mint\u001b[39m):\n\u001b[1;32m    127\u001b[0m     index \u001b[39m=\u001b[39m pandas\u001b[39m.\u001b[39mRangeIndex(index_len)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/modin/core/execution/dask/common/engine_wrapper.py:70\u001b[0m, in \u001b[0;36mDaskWrapper.materialize\u001b[0;34m(cls, future)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[39mMaterialize data matching `future` object.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[39m    An object(s) from the distributed memory.\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     69\u001b[0m client \u001b[39m=\u001b[39m default_client()\n\u001b[0;32m---> 70\u001b[0m \u001b[39mreturn\u001b[39;00m client\u001b[39m.\u001b[39;49mgather(future)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/distributed/client.py:1969\u001b[0m, in \u001b[0;36mClient.gather\u001b[0;34m(self, futures, errors, direct, asynchronous)\u001b[0m\n\u001b[1;32m   1967\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1968\u001b[0m     local_worker \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1969\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msync(\n\u001b[1;32m   1970\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_gather,\n\u001b[1;32m   1971\u001b[0m     futures,\n\u001b[1;32m   1972\u001b[0m     errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m   1973\u001b[0m     direct\u001b[39m=\u001b[39;49mdirect,\n\u001b[1;32m   1974\u001b[0m     local_worker\u001b[39m=\u001b[39;49mlocal_worker,\n\u001b[1;32m   1975\u001b[0m     asynchronous\u001b[39m=\u001b[39;49masynchronous,\n\u001b[1;32m   1976\u001b[0m )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/distributed/client.py:865\u001b[0m, in \u001b[0;36mClient.sync\u001b[0;34m(self, func, asynchronous, callback_timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m    863\u001b[0m     \u001b[39mreturn\u001b[39;00m future\n\u001b[1;32m    864\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 865\u001b[0m     \u001b[39mreturn\u001b[39;00m sync(\n\u001b[1;32m    866\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloop, func, \u001b[39m*\u001b[39;49margs, callback_timeout\u001b[39m=\u001b[39;49mcallback_timeout, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    867\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/distributed/utils.py:327\u001b[0m, in \u001b[0;36msync\u001b[0;34m(loop, func, callback_timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[39mif\u001b[39;00m error[\u001b[39m0\u001b[39m]:\n\u001b[1;32m    326\u001b[0m     typ, exc, tb \u001b[39m=\u001b[39m error[\u001b[39m0\u001b[39m]\n\u001b[0;32m--> 327\u001b[0m     \u001b[39mraise\u001b[39;00m exc\u001b[39m.\u001b[39mwith_traceback(tb)\n\u001b[1;32m    328\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    329\u001b[0m     \u001b[39mreturn\u001b[39;00m result[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/distributed/utils.py:310\u001b[0m, in \u001b[0;36msync.<locals>.f\u001b[0;34m()\u001b[0m\n\u001b[1;32m    308\u001b[0m     \u001b[39mif\u001b[39;00m callback_timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    309\u001b[0m         future \u001b[39m=\u001b[39m asyncio\u001b[39m.\u001b[39mwait_for(future, callback_timeout)\n\u001b[0;32m--> 310\u001b[0m     result[\u001b[39m0\u001b[39m] \u001b[39m=\u001b[39m \u001b[39myield\u001b[39;00m future\n\u001b[1;32m    311\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m    312\u001b[0m     error[\u001b[39m0\u001b[39m] \u001b[39m=\u001b[39m sys\u001b[39m.\u001b[39mexc_info()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/tornado/gen.py:769\u001b[0m, in \u001b[0;36mRunner.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    766\u001b[0m exc_info \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    768\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 769\u001b[0m     value \u001b[39m=\u001b[39m future\u001b[39m.\u001b[39;49mresult()\n\u001b[1;32m    770\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m    771\u001b[0m     exc_info \u001b[39m=\u001b[39m sys\u001b[39m.\u001b[39mexc_info()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/distributed/client.py:1834\u001b[0m, in \u001b[0;36mClient._gather\u001b[0;34m(self, futures, errors, direct, local_worker)\u001b[0m\n\u001b[1;32m   1832\u001b[0m         exc \u001b[39m=\u001b[39m CancelledError(key)\n\u001b[1;32m   1833\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1834\u001b[0m         \u001b[39mraise\u001b[39;00m exception\u001b[39m.\u001b[39mwith_traceback(traceback)\n\u001b[1;32m   1835\u001b[0m     \u001b[39mraise\u001b[39;00m exc\n\u001b[1;32m   1836\u001b[0m \u001b[39mif\u001b[39;00m errors \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mskip\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "\u001b[0;31mKilledWorker\u001b[0m: ('parse-d6e9b0b42113e9ec9cc94cf6a479de0b', <WorkerState 'tcp://127.0.0.1:55891', name: 8, status: closed, memory: 0, processing: 1>)"
     ]
    }
   ],
   "source": [
    "#import pandas\n",
    "import modin.pandas as pd\n",
    "import modin\n",
    "import os\n",
    "os.environ[\"MODIN_ENGINE\"] = \"Dask\"  # Modin will use Dask\n",
    "# ray.init()\n",
    "#ray.init(ignore_reinit_error=True)\n",
    "# print(modin.config.Engine.get())\n",
    "# print(modin.config.NPartitions.get())\n",
    "# print(modin.config.Engine.put('Ray'))\n",
    "# print(modin.config.Engine.get())\n",
    "# It gives errors if I try to print these now \n",
    "data_path = \"data/full/\"\n",
    "import time\n",
    "start = time.time()\n",
    "df_tags = pd.read_feather(path= data_path + \"yt_metadata_tags.feather\", use_threads=True)\n",
    "stop = time.time()\n",
    "print('Time: ', stop - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  54.73409914970398\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "data_path = \"data/full/\"\n",
    "start = time.time()\n",
    "df_tags = pd.read_feather(path= data_path + \"yt_metadata_tags.feather\", use_threads=True)\n",
    "stop = time.time()\n",
    "print('Time: ', stop - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [3], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# So, on ssd im able to use modin with ray and it's incredibly fast on apply method but incredibly slow on head() and info() because of ssd bottleneck\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m# and how it has to aggregate things in a single node\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# on disk Its much faster to load the data with normal pandas but im having bugs trying to use modin. With ray it doesnt work and with dask the division of \u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39m# work makes the load fail\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39m# let's just use pandas and see how slow the apply is\u001b[39;00m\n\u001b[1;32m      6\u001b[0m start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m----> 7\u001b[0m df_tags \u001b[39m=\u001b[39m df_tags[\u001b[39m'\u001b[39;49m\u001b[39mtags\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mapply(\u001b[39mlambda\u001b[39;49;00m x: x\u001b[39m.\u001b[39;49msplit(\u001b[39m\"\u001b[39;49m\u001b[39m,\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n\u001b[1;32m      8\u001b[0m stop \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m      9\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mTime: \u001b[39m\u001b[39m'\u001b[39m, stop \u001b[39m-\u001b[39m start)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/pandas/core/series.py:4433\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4323\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[1;32m   4324\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   4325\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4328\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   4329\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[1;32m   4330\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   4331\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4332\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4431\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4432\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4433\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\u001b[39mself\u001b[39;49m, func, convert_dtype, args, kwargs)\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/pandas/core/apply.py:1088\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1084\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf, \u001b[39mstr\u001b[39m):\n\u001b[1;32m   1085\u001b[0m     \u001b[39m# if we are a string, try to dispatch\u001b[39;00m\n\u001b[1;32m   1086\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[0;32m-> 1088\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/pandas/core/apply.py:1143\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1137\u001b[0m         values \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m)\u001b[39m.\u001b[39m_values\n\u001b[1;32m   1138\u001b[0m         \u001b[39m# error: Argument 2 to \"map_infer\" has incompatible type\u001b[39;00m\n\u001b[1;32m   1139\u001b[0m         \u001b[39m# \"Union[Callable[..., Any], str, List[Union[Callable[..., Any], str]],\u001b[39;00m\n\u001b[1;32m   1140\u001b[0m         \u001b[39m# Dict[Hashable, Union[Union[Callable[..., Any], str],\u001b[39;00m\n\u001b[1;32m   1141\u001b[0m         \u001b[39m# List[Union[Callable[..., Any], str]]]]]\"; expected\u001b[39;00m\n\u001b[1;32m   1142\u001b[0m         \u001b[39m# \"Callable[[Any], Any]\"\u001b[39;00m\n\u001b[0;32m-> 1143\u001b[0m         mapped \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mmap_infer(\n\u001b[1;32m   1144\u001b[0m             values,\n\u001b[1;32m   1145\u001b[0m             f,  \u001b[39m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1146\u001b[0m             convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype,\n\u001b[1;32m   1147\u001b[0m         )\n\u001b[1;32m   1149\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1150\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1151\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1152\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/pandas/_libs/lib.pyx:2870\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn [3], line 7\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# So, on ssd im able to use modin with ray and it's incredibly fast on apply method but incredibly slow on head() and info() because of ssd bottleneck\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m# and how it has to aggregate things in a single node\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# on disk Its much faster to load the data with normal pandas but im having bugs trying to use modin. With ray it doesnt work and with dask the division of \u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39m# work makes the load fail\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39m# let's just use pandas and see how slow the apply is\u001b[39;00m\n\u001b[1;32m      6\u001b[0m start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m----> 7\u001b[0m df_tags \u001b[39m=\u001b[39m df_tags[\u001b[39m'\u001b[39m\u001b[39mtags\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: x\u001b[39m.\u001b[39;49msplit(\u001b[39m\"\u001b[39;49m\u001b[39m,\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n\u001b[1;32m      8\u001b[0m stop \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m      9\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mTime: \u001b[39m\u001b[39m'\u001b[39m, stop \u001b[39m-\u001b[39m start)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# So, on ssd im able to use modin with ray and it's incredibly fast on apply method but incredibly slow on head() and info() because of ssd bottleneck\n",
    "# and how it has to aggregate things in a single node\n",
    "# on disk Its much faster to load the data with normal pandas but im having bugs trying to use modin. With ray it doesnt work and with dask the division of \n",
    "# work makes the load fail\n",
    "# let's just use pandas and see how slow the apply is\n",
    "start = time.time()\n",
    "#df_tags = df_tags['tags'].apply(lambda x: x.split(\",\")) # I stopped at 1min 30s, clearly much slower and even more memory consuming, it tries to copy everything in ram\n",
    "stop = time.time()\n",
    "print('Time: ', stop - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'modin'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmodin\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconfig\u001b[39;00m \u001b[39mimport\u001b[39;00m Engine\n\u001b[1;32m      2\u001b[0m Engine\u001b[39m.\u001b[39mput(\u001b[39m\"\u001b[39m\u001b[39mRay\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmodin\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'modin'"
     ]
    }
   ],
   "source": [
    "\n",
    "from modin.config import Engine\n",
    "Engine.put(\"Ray\")\n",
    "import modin.pandas as pd\n",
    "\n",
    "import os\n",
    "os.environ.items()\n",
    "modin.config.Engine.get() \n",
    "# was having issues, I found that conda install modin modin-all modin-ray -c conda-forge  \n",
    "#  conda install grpcio -c conda-forge          this needs to be installed from conda and not pip for my mac to work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Please `pip install modin[ray]` to install compatible Ray version (>=1.4.0,<1.13.0).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/modin/config/pubsub.py:253\u001b[0m, in \u001b[0;36mParameter.get\u001b[0;34m(cls)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 253\u001b[0m     raw \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_get_raw_from_config()\n\u001b[1;32m    254\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/modin/config/envvars.py:46\u001b[0m, in \u001b[0;36mEnvironmentVariable._get_raw_from_config\u001b[0;34m(cls)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[39mRead the value from environment variable.\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[39m    If value is absent.\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m \u001b[39mreturn\u001b[39;00m os\u001b[39m.\u001b[39;49menviron[\u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mvarname]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/os.py:680\u001b[0m, in \u001b[0;36m_Environ.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n\u001b[1;32m    679\u001b[0m     \u001b[39m# raise KeyError with the original key value\u001b[39;00m\n\u001b[0;32m--> 680\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m    681\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecodevalue(value)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'MODIN_ENGINE'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmodin\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmodin\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconfig\u001b[39;00m \u001b[39mimport\u001b[39;00m Engine\n\u001b[0;32m----> 5\u001b[0m \u001b[39mprint\u001b[39m(modin\u001b[39m.\u001b[39;49mconfig\u001b[39m.\u001b[39;49mEngine\u001b[39m.\u001b[39;49mget()) \u001b[39m# dask\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39m# ray is only in pip, installed at the end, rest is conda-forge\u001b[39;00m\n\u001b[1;32m      7\u001b[0m Engine\u001b[39m.\u001b[39mput(\u001b[39m\"\u001b[39m\u001b[39mRay\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/modin/config/pubsub.py:255\u001b[0m, in \u001b[0;36mParameter.get\u001b[0;34m(cls)\u001b[0m\n\u001b[1;32m    253\u001b[0m     raw \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_get_raw_from_config()\n\u001b[1;32m    254\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n\u001b[0;32m--> 255\u001b[0m     \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_value \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_get_default()\n\u001b[1;32m    256\u001b[0m     \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_value_source \u001b[39m=\u001b[39m ValueSource\u001b[39m.\u001b[39mDEFAULT\n\u001b[1;32m    257\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/modin/config/envvars.py:102\u001b[0m, in \u001b[0;36mEngine._get_default\u001b[0;34m(cls)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     98\u001b[0m     \u001b[39mif\u001b[39;00m (\n\u001b[1;32m     99\u001b[0m         version\u001b[39m.\u001b[39mparse(ray\u001b[39m.\u001b[39m__version__) \u001b[39m<\u001b[39m MIN_RAY_VERSION\n\u001b[1;32m    100\u001b[0m         \u001b[39mor\u001b[39;00m version\u001b[39m.\u001b[39mparse(ray\u001b[39m.\u001b[39m__version__) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m MAX_RAY_VERSION_EXCLUSIVE\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[0;32m--> 102\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\n\u001b[1;32m    103\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mPlease `pip install modin[ray]` to install compatible Ray \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    104\u001b[0m             \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mversion \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    105\u001b[0m             \u001b[39m+\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(>=\u001b[39m\u001b[39m{\u001b[39;00mMIN_RAY_VERSION\u001b[39m}\u001b[39;00m\u001b[39m,<\u001b[39m\u001b[39m{\u001b[39;00mMAX_RAY_VERSION_EXCLUSIVE\u001b[39m}\u001b[39;00m\u001b[39m).\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    106\u001b[0m         )\n\u001b[1;32m    107\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mRay\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    108\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[0;31mImportError\u001b[0m: Please `pip install modin[ray]` to install compatible Ray version (>=1.4.0,<1.13.0)."
     ]
    }
   ],
   "source": [
    "# why not detected anymore?? -- ok finally, had to reinstall everything from scratch and force-reinstall\n",
    "import numpy as np\n",
    "import modin\n",
    "from modin.config import Engine\n",
    "print(modin.config.Engine.get()) # dask\n",
    "# ray is only in pip, installed at the end, rest is conda-forge\n",
    "Engine.put(\"Ray\")\n",
    "print(modin.config.Engine.get()) # ray\n",
    "import modin.pandas as pd\n",
    "import time\n",
    "data_path = \"data/full/\"\n",
    "start = time.time()\n",
    "df_tags = pd.read_feather(path= data_path + \"yt_metadata_tags.feather\", use_threads=True) \n",
    "stop = time.time()\n",
    "print('Time: ', stop - start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ray\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Ray execution environment not yet initialized. Initializing...\n",
      "To remove this warning, run the following python code before doing dataframe operations:\n",
      "\n",
      "    import ray\n",
      "    ray.init()\n",
      "\n",
      "DeprecationWarning: `ray.ray_constants.MAC_DEGRADED_PERF_MMAP_SIZE_LIMIT` is a private attribute and access will be removed in a future Ray version.\n",
      "UserWarning: On Macs, Ray's performance is known to degrade with object store size greater than 2.0 GiB. Ray by default does not allow setting an object store size greater than that. Modin is overriding that default limit because it would rather have a larger, slower object store than spill to disk more often. To override Modin's behavior, you can initialize Ray yourself.\n",
      "2022-12-12 17:27:57,143\tINFO worker.py:1528 -- Started a local Ray instance.\n",
      "2022-12-12 17:27:57,929\tWARNING __init__.py:191 -- DeprecationWarning: `ray.worker.global_worker` is a private attribute and access will be removed in a future Ray version.\n"
     ]
    }
   ],
   "source": [
    "# OK so, if I run it once and install things as I go, it works. If I try to run it again, it doesn't work.\n",
    "import os \n",
    "os.environ.setdefault(\"MODIN_ENGINE\", \"Ray\") # basically I need to set this before importing modin every time else it doesn't work -- still not that fast\n",
    "#os.environ.setdefault(\"MODIN_ENGINE\", \"Dask\") # but this doesn't work either to read the data... what should I doooooo\n",
    "import modin.pandas as pd\n",
    "import modin\n",
    "from modin.config import Engine\n",
    "print(modin.config.Engine.get()) # dask\n",
    "import time\n",
    "data_path = \"data/full/\"\n",
    "start = time.time()\n",
    "df_tags = pd.read_feather(path= data_path + \"yt_metadata_tags.feather\", use_threads=True)\n",
    "stop = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  273.02896904945374\n"
     ]
    }
   ],
   "source": [
    "print('Time: ', stop - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  2.6469740867614746\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "df_tags = df_tags['tags'].apply(lambda x: x.split(\",\"))\n",
    "stop = time.time()\n",
    "print('Time: ', stop - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m----> 2\u001b[0m \u001b[39mprint\u001b[39;49m(df_tags\u001b[39m.\u001b[39;49mhead())\n\u001b[1;32m      3\u001b[0m stop \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m      4\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mTime: \u001b[39m\u001b[39m'\u001b[39m, stop \u001b[39m-\u001b[39m start)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/modin/logging/logger_metaclass.py:68\u001b[0m, in \u001b[0;36mlogger_class_wrapper.<locals>.log_wrap\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     66\u001b[0m     logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEND::PANDAS-API::\u001b[39m\u001b[39m{\u001b[39;00mclass_name\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mmethod_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     67\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n\u001b[0;32m---> 68\u001b[0m \u001b[39mreturn\u001b[39;00m method(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/modin/pandas/base.py:3831\u001b[0m, in \u001b[0;36mBasePandasDataset.__str__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3823\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__str__\u001b[39m(\u001b[39mself\u001b[39m):  \u001b[39m# pragma: no cover\u001b[39;00m\n\u001b[1;32m   3824\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   3825\u001b[0m \u001b[39m    Return str(self).\u001b[39;00m\n\u001b[1;32m   3826\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3829\u001b[0m \u001b[39m    str\u001b[39;00m\n\u001b[1;32m   3830\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3831\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mrepr\u001b[39;49m(\u001b[39mself\u001b[39;49m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/modin/logging/logger_metaclass.py:68\u001b[0m, in \u001b[0;36mlogger_class_wrapper.<locals>.log_wrap\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     66\u001b[0m     logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEND::PANDAS-API::\u001b[39m\u001b[39m{\u001b[39;00mclass_name\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mmethod_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     67\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n\u001b[0;32m---> 68\u001b[0m \u001b[39mreturn\u001b[39;00m method(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/modin/pandas/series.py:419\u001b[0m, in \u001b[0;36mSeries.__repr__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    417\u001b[0m num_rows \u001b[39m=\u001b[39m pandas\u001b[39m.\u001b[39mget_option(\u001b[39m\"\u001b[39m\u001b[39mdisplay.max_rows\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mor\u001b[39;00m \u001b[39m60\u001b[39m\n\u001b[1;32m    418\u001b[0m num_cols \u001b[39m=\u001b[39m pandas\u001b[39m.\u001b[39mget_option(\u001b[39m\"\u001b[39m\u001b[39mdisplay.max_columns\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mor\u001b[39;00m \u001b[39m20\u001b[39m\n\u001b[0;32m--> 419\u001b[0m temp_df \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_build_repr_df(num_rows, num_cols)\n\u001b[1;32m    420\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(temp_df, pandas\u001b[39m.\u001b[39mDataFrame) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m temp_df\u001b[39m.\u001b[39mempty:\n\u001b[1;32m    421\u001b[0m     temp_df \u001b[39m=\u001b[39m temp_df\u001b[39m.\u001b[39miloc[:, \u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/modin/logging/logger_metaclass.py:68\u001b[0m, in \u001b[0;36mlogger_class_wrapper.<locals>.log_wrap\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     66\u001b[0m     logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEND::PANDAS-API::\u001b[39m\u001b[39m{\u001b[39;00mclass_name\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mmethod_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     67\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n\u001b[0;32m---> 68\u001b[0m \u001b[39mreturn\u001b[39;00m method(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/modin/pandas/base.py:203\u001b[0m, in \u001b[0;36mBasePandasDataset._build_repr_df\u001b[0;34m(self, num_rows, num_cols)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     indexer \u001b[39m=\u001b[39m row_indexer\n\u001b[0;32m--> 203\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miloc[indexer]\u001b[39m.\u001b[39;49m_query_compiler\u001b[39m.\u001b[39;49mto_pandas()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/modin/logging/logger_metaclass.py:68\u001b[0m, in \u001b[0;36mlogger_class_wrapper.<locals>.log_wrap\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     66\u001b[0m     logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEND::PANDAS-API::\u001b[39m\u001b[39m{\u001b[39;00mclass_name\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mmethod_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     67\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n\u001b[0;32m---> 68\u001b[0m \u001b[39mreturn\u001b[39;00m method(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/modin/core/storage_formats/pandas/query_compiler.py:259\u001b[0m, in \u001b[0;36mPandasQueryCompiler.to_pandas\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mto_pandas\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 259\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_modin_frame\u001b[39m.\u001b[39;49mto_pandas()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/modin/logging/logger_metaclass.py:68\u001b[0m, in \u001b[0;36mlogger_class_wrapper.<locals>.log_wrap\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     66\u001b[0m     logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEND::PANDAS-API::\u001b[39m\u001b[39m{\u001b[39;00mclass_name\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mmethod_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     67\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n\u001b[0;32m---> 68\u001b[0m \u001b[39mreturn\u001b[39;00m method(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/modin/core/dataframe/pandas/dataframe/dataframe.py:115\u001b[0m, in \u001b[0;36mlazy_metadata_decorator.<locals>.decorator.<locals>.run_f_on_minimally_updated_metadata\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[39melif\u001b[39;00m apply_axis \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrows\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    114\u001b[0m         obj\u001b[39m.\u001b[39m_propagate_index_objs(axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m--> 115\u001b[0m result \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    116\u001b[0m \u001b[39mif\u001b[39;00m apply_axis \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m transpose:\n\u001b[1;32m    117\u001b[0m     result\u001b[39m.\u001b[39m_deferred_index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_deferred_index\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/modin/core/dataframe/pandas/dataframe/dataframe.py:2835\u001b[0m, in \u001b[0;36mPandasDataframe.to_pandas\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2826\u001b[0m \u001b[39m@lazy_metadata_decorator\u001b[39m(apply_axis\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mboth\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   2827\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mto_pandas\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m   2828\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2829\u001b[0m \u001b[39m    Convert this Modin DataFrame to a pandas DataFrame.\u001b[39;00m\n\u001b[1;32m   2830\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2833\u001b[0m \u001b[39m    pandas.DataFrame\u001b[39;00m\n\u001b[1;32m   2834\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2835\u001b[0m     df \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_partition_mgr_cls\u001b[39m.\u001b[39;49mto_pandas(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_partitions)\n\u001b[1;32m   2836\u001b[0m     \u001b[39mif\u001b[39;00m df\u001b[39m.\u001b[39mempty:\n\u001b[1;32m   2837\u001b[0m         df \u001b[39m=\u001b[39m pandas\u001b[39m.\u001b[39mDataFrame(columns\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns, index\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/modin/core/dataframe/pandas/partitioning/partition_manager.py:639\u001b[0m, in \u001b[0;36mPandasDataframePartitionManager.to_pandas\u001b[0;34m(cls, partitions)\u001b[0m\n\u001b[1;32m    624\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    625\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mto_pandas\u001b[39m(\u001b[39mcls\u001b[39m, partitions):\n\u001b[1;32m    626\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    627\u001b[0m \u001b[39m    Convert NumPy array of PandasDataframePartition to pandas DataFrame.\u001b[39;00m\n\u001b[1;32m    628\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    637\u001b[0m \u001b[39m        A pandas DataFrame\u001b[39;00m\n\u001b[1;32m    638\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 639\u001b[0m     retrieved_objects \u001b[39m=\u001b[39m [[obj\u001b[39m.\u001b[39mto_pandas() \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m part] \u001b[39mfor\u001b[39;00m part \u001b[39min\u001b[39;00m partitions]\n\u001b[1;32m    640\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mall\u001b[39m(\n\u001b[1;32m    641\u001b[0m         \u001b[39misinstance\u001b[39m(part, pandas\u001b[39m.\u001b[39mSeries) \u001b[39mfor\u001b[39;00m row \u001b[39min\u001b[39;00m retrieved_objects \u001b[39mfor\u001b[39;00m part \u001b[39min\u001b[39;00m row\n\u001b[1;32m    642\u001b[0m     ):\n\u001b[1;32m    643\u001b[0m         axis \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/modin/core/dataframe/pandas/partitioning/partition_manager.py:639\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    624\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    625\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mto_pandas\u001b[39m(\u001b[39mcls\u001b[39m, partitions):\n\u001b[1;32m    626\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    627\u001b[0m \u001b[39m    Convert NumPy array of PandasDataframePartition to pandas DataFrame.\u001b[39;00m\n\u001b[1;32m    628\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    637\u001b[0m \u001b[39m        A pandas DataFrame\u001b[39;00m\n\u001b[1;32m    638\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 639\u001b[0m     retrieved_objects \u001b[39m=\u001b[39m [[obj\u001b[39m.\u001b[39mto_pandas() \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m part] \u001b[39mfor\u001b[39;00m part \u001b[39min\u001b[39;00m partitions]\n\u001b[1;32m    640\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mall\u001b[39m(\n\u001b[1;32m    641\u001b[0m         \u001b[39misinstance\u001b[39m(part, pandas\u001b[39m.\u001b[39mSeries) \u001b[39mfor\u001b[39;00m row \u001b[39min\u001b[39;00m retrieved_objects \u001b[39mfor\u001b[39;00m part \u001b[39min\u001b[39;00m row\n\u001b[1;32m    642\u001b[0m     ):\n\u001b[1;32m    643\u001b[0m         axis \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/modin/core/dataframe/pandas/partitioning/partition_manager.py:639\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    624\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    625\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mto_pandas\u001b[39m(\u001b[39mcls\u001b[39m, partitions):\n\u001b[1;32m    626\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    627\u001b[0m \u001b[39m    Convert NumPy array of PandasDataframePartition to pandas DataFrame.\u001b[39;00m\n\u001b[1;32m    628\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    637\u001b[0m \u001b[39m        A pandas DataFrame\u001b[39;00m\n\u001b[1;32m    638\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 639\u001b[0m     retrieved_objects \u001b[39m=\u001b[39m [[obj\u001b[39m.\u001b[39;49mto_pandas() \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m part] \u001b[39mfor\u001b[39;00m part \u001b[39min\u001b[39;00m partitions]\n\u001b[1;32m    640\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mall\u001b[39m(\n\u001b[1;32m    641\u001b[0m         \u001b[39misinstance\u001b[39m(part, pandas\u001b[39m.\u001b[39mSeries) \u001b[39mfor\u001b[39;00m row \u001b[39min\u001b[39;00m retrieved_objects \u001b[39mfor\u001b[39;00m part \u001b[39min\u001b[39;00m row\n\u001b[1;32m    642\u001b[0m     ):\n\u001b[1;32m    643\u001b[0m         axis \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/modin/core/dataframe/pandas/partitioning/partition.py:125\u001b[0m, in \u001b[0;36mPandasDataframePartition.to_pandas\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mto_pandas\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    113\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[39m    Convert the object wrapped by this partition to a ``pandas.DataFrame``.\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[39m    only need to call `get`.\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 125\u001b[0m     dataframe \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget()\n\u001b[1;32m    126\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(dataframe, (pandas\u001b[39m.\u001b[39mDataFrame, pandas\u001b[39m.\u001b[39mSeries))\n\u001b[1;32m    127\u001b[0m     \u001b[39mreturn\u001b[39;00m dataframe\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/modin/core/execution/ray/implementations/pandas_on_ray/partitioning/partition.py:80\u001b[0m, in \u001b[0;36mPandasOnRayDataframePartition.get\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcall_queue):\n\u001b[1;32m     79\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdrain_call_queue()\n\u001b[0;32m---> 80\u001b[0m result \u001b[39m=\u001b[39m ray\u001b[39m.\u001b[39;49mget(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moid)\n\u001b[1;32m     81\u001b[0m logger\u001b[39m.\u001b[39mdebug(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEXIT::Partition.get::\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_identity\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     82\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/ray/_private/client_mode_hook.py:105\u001b[0m, in \u001b[0;36mclient_mode_hook.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[39mif\u001b[39;00m func\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39minit\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m is_client_mode_enabled_by_default:\n\u001b[1;32m    104\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39m(ray, func\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 105\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/ray/_private/worker.py:2283\u001b[0m, in \u001b[0;36mget\u001b[0;34m(object_refs, timeout)\u001b[0m\n\u001b[1;32m   2278\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   2279\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mobject_refs\u001b[39m\u001b[39m'\u001b[39m\u001b[39m must either be an ObjectRef or a list of ObjectRefs.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2280\u001b[0m     )\n\u001b[1;32m   2282\u001b[0m \u001b[39m# TODO(ujvl): Consider how to allow user to retrieve the ready objects.\u001b[39;00m\n\u001b[0;32m-> 2283\u001b[0m values, debugger_breakpoint \u001b[39m=\u001b[39m worker\u001b[39m.\u001b[39;49mget_objects(object_refs, timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m   2284\u001b[0m \u001b[39mfor\u001b[39;00m i, value \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(values):\n\u001b[1;32m   2285\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(value, RayError):\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/ray/_private/worker.py:668\u001b[0m, in \u001b[0;36mWorker.get_objects\u001b[0;34m(self, object_refs, timeout)\u001b[0m\n\u001b[1;32m    662\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m    663\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mAttempting to call `get` on the value \u001b[39m\u001b[39m{\u001b[39;00mobject_ref\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    664\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mwhich is not an ray.ObjectRef.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    665\u001b[0m         )\n\u001b[1;32m    667\u001b[0m timeout_ms \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(timeout \u001b[39m*\u001b[39m \u001b[39m1000\u001b[39m) \u001b[39mif\u001b[39;00m timeout \u001b[39melse\u001b[39;00m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m--> 668\u001b[0m data_metadata_pairs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcore_worker\u001b[39m.\u001b[39;49mget_objects(\n\u001b[1;32m    669\u001b[0m     object_refs, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcurrent_task_id, timeout_ms\n\u001b[1;32m    670\u001b[0m )\n\u001b[1;32m    671\u001b[0m debugger_breakpoint \u001b[39m=\u001b[39m \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    672\u001b[0m \u001b[39mfor\u001b[39;00m (data, metadata) \u001b[39min\u001b[39;00m data_metadata_pairs:\n",
      "File \u001b[0;32mpython/ray/_raylet.pyx:1445\u001b[0m, in \u001b[0;36mray._raylet.CoreWorker.get_objects\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpython/ray/_raylet.pyx:190\u001b[0m, in \u001b[0;36mray._raylet.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "#print(df_tags.head()) # Again dangerouussss\n",
    "stop = time.time()\n",
    "print('Time: ', stop - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "UFuncTypeError",
     "evalue": "ufunc 'less' did not contain a loop with signature matching types (<class 'numpy.dtype[str_]'>, <class 'numpy.dtype[int64]'>) -> <class 'numpy.dtype[bool_]'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUFuncTypeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/modin/pandas/series.py:2471\u001b[0m, in \u001b[0;36mSeries._getitem\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2470\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 2471\u001b[0m         result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_query_compiler\u001b[39m.\u001b[39;49mgetitem_row_array(key)\n\u001b[1;32m   2472\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/modin/logging/logger_metaclass.py:68\u001b[0m, in \u001b[0;36mlogger_class_wrapper.<locals>.log_wrap\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n\u001b[0;32m---> 68\u001b[0m \u001b[39mreturn\u001b[39;00m method(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/modin/core/storage_formats/pandas/query_compiler.py:2182\u001b[0m, in \u001b[0;36mPandasQueryCompiler.getitem_row_array\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2181\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgetitem_row_array\u001b[39m(\u001b[39mself\u001b[39m, key):\n\u001b[0;32m-> 2182\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__constructor__(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_modin_frame\u001b[39m.\u001b[39;49mmask(row_positions\u001b[39m=\u001b[39;49mkey))\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/modin/logging/logger_metaclass.py:68\u001b[0m, in \u001b[0;36mlogger_class_wrapper.<locals>.log_wrap\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n\u001b[0;32m---> 68\u001b[0m \u001b[39mreturn\u001b[39;00m method(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/modin/core/dataframe/pandas/dataframe/dataframe.py:115\u001b[0m, in \u001b[0;36mlazy_metadata_decorator.<locals>.decorator.<locals>.run_f_on_minimally_updated_metadata\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m         obj\u001b[39m.\u001b[39m_propagate_index_objs(axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m--> 115\u001b[0m result \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    116\u001b[0m \u001b[39mif\u001b[39;00m apply_axis \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m transpose:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/modin/core/dataframe/pandas/dataframe/dataframe.py:645\u001b[0m, in \u001b[0;36mPandasDataframe.mask\u001b[0;34m(self, row_labels, row_positions, col_labels, col_positions)\u001b[0m\n\u001b[1;32m    643\u001b[0m \u001b[39m# Get dict of row_parts as {row_index: row_internal_indices}\u001b[39;00m\n\u001b[1;32m    644\u001b[0m \u001b[39m# TODO: Rename `row_partitions_list`->`row_partitions_dict`\u001b[39;00m\n\u001b[0;32m--> 645\u001b[0m row_partitions_list \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_dict_of_block_index(\n\u001b[1;32m    646\u001b[0m     \u001b[39m0\u001b[39;49m, sorted_row_positions, are_indices_sorted\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[1;32m    647\u001b[0m )\n\u001b[1;32m    648\u001b[0m new_row_lengths \u001b[39m=\u001b[39m [\n\u001b[1;32m    649\u001b[0m     \u001b[39mlen\u001b[39m(\n\u001b[1;32m    650\u001b[0m         \u001b[39m# Row lengths for slice are calculated as the length of the slice\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    657\u001b[0m     \u001b[39mfor\u001b[39;00m part_idx, part_indexer \u001b[39min\u001b[39;00m row_partitions_list\u001b[39m.\u001b[39mitems()\n\u001b[1;32m    658\u001b[0m ]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/modin/logging/logger_metaclass.py:68\u001b[0m, in \u001b[0;36mlogger_class_wrapper.<locals>.log_wrap\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n\u001b[0;32m---> 68\u001b[0m \u001b[39mreturn\u001b[39;00m method(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/modin/core/dataframe/pandas/dataframe/dataframe.py:1216\u001b[0m, in \u001b[0;36mPandasDataframe._get_dict_of_block_index\u001b[0;34m(self, axis, indices, are_indices_sorted)\u001b[0m\n\u001b[1;32m   1215\u001b[0m     indices \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(indices, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mint64)\n\u001b[0;32m-> 1216\u001b[0m negative_mask \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mless(indices, \u001b[39m0\u001b[39;49m)\n\u001b[1;32m   1217\u001b[0m has_negative \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39many(negative_mask)\n",
      "\u001b[0;31mUFuncTypeError\u001b[0m: ufunc 'less' did not contain a loop with signature matching types (<class 'numpy.dtype[str_]'>, <class 'numpy.dtype[int64]'>) -> <class 'numpy.dtype[bool_]'>",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mUFuncTypeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [8], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m      6\u001b[0m \u001b[39m# lowercase\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m df_tags[\u001b[39m'\u001b[39m\u001b[39mtags\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df_tags[\u001b[39m'\u001b[39;49m\u001b[39mtags\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: [tag\u001b[39m.\u001b[39mlower() \u001b[39mfor\u001b[39;00m tag \u001b[39min\u001b[39;00m x])\n\u001b[1;32m      8\u001b[0m le \u001b[39m=\u001b[39m LabelEncoder()\n\u001b[1;32m      9\u001b[0m tags \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/modin/logging/logger_metaclass.py:68\u001b[0m, in \u001b[0;36mlogger_class_wrapper.<locals>.log_wrap\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     66\u001b[0m     logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEND::PANDAS-API::\u001b[39m\u001b[39m{\u001b[39;00mclass_name\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mmethod_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     67\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n\u001b[0;32m---> 68\u001b[0m \u001b[39mreturn\u001b[39;00m method(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/modin/pandas/base.py:3650\u001b[0m, in \u001b[0;36mBasePandasDataset.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3648\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_slice(indexer)\n\u001b[1;32m   3649\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 3650\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem(key)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/modin/logging/logger_metaclass.py:68\u001b[0m, in \u001b[0;36mlogger_class_wrapper.<locals>.log_wrap\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     66\u001b[0m     logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEND::PANDAS-API::\u001b[39m\u001b[39m{\u001b[39;00mclass_name\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mmethod_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     67\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n\u001b[0;32m---> 68\u001b[0m \u001b[39mreturn\u001b[39;00m method(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/modin/pandas/series.py:2473\u001b[0m, in \u001b[0;36mSeries._getitem\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2471\u001b[0m             result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_query_compiler\u001b[39m.\u001b[39mgetitem_row_array(key)\n\u001b[1;32m   2472\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m-> 2473\u001b[0m         result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_query_compiler\u001b[39m.\u001b[39;49mgetitem_row_array(key)\n\u001b[1;32m   2474\u001b[0m \u001b[39mif\u001b[39;00m reduce_dimension:\n\u001b[1;32m   2475\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reduce_dimension(result)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/modin/logging/logger_metaclass.py:68\u001b[0m, in \u001b[0;36mlogger_class_wrapper.<locals>.log_wrap\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     66\u001b[0m     logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEND::PANDAS-API::\u001b[39m\u001b[39m{\u001b[39;00mclass_name\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mmethod_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     67\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n\u001b[0;32m---> 68\u001b[0m \u001b[39mreturn\u001b[39;00m method(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/modin/core/storage_formats/pandas/query_compiler.py:2182\u001b[0m, in \u001b[0;36mPandasQueryCompiler.getitem_row_array\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2181\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgetitem_row_array\u001b[39m(\u001b[39mself\u001b[39m, key):\n\u001b[0;32m-> 2182\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__constructor__(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_modin_frame\u001b[39m.\u001b[39;49mmask(row_positions\u001b[39m=\u001b[39;49mkey))\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/modin/logging/logger_metaclass.py:68\u001b[0m, in \u001b[0;36mlogger_class_wrapper.<locals>.log_wrap\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     66\u001b[0m     logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEND::PANDAS-API::\u001b[39m\u001b[39m{\u001b[39;00mclass_name\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mmethod_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     67\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n\u001b[0;32m---> 68\u001b[0m \u001b[39mreturn\u001b[39;00m method(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/modin/core/dataframe/pandas/dataframe/dataframe.py:115\u001b[0m, in \u001b[0;36mlazy_metadata_decorator.<locals>.decorator.<locals>.run_f_on_minimally_updated_metadata\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[39melif\u001b[39;00m apply_axis \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrows\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    114\u001b[0m         obj\u001b[39m.\u001b[39m_propagate_index_objs(axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m--> 115\u001b[0m result \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    116\u001b[0m \u001b[39mif\u001b[39;00m apply_axis \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m transpose:\n\u001b[1;32m    117\u001b[0m     result\u001b[39m.\u001b[39m_deferred_index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_deferred_index\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/modin/core/dataframe/pandas/dataframe/dataframe.py:645\u001b[0m, in \u001b[0;36mPandasDataframe.mask\u001b[0;34m(self, row_labels, row_positions, col_labels, col_positions)\u001b[0m\n\u001b[1;32m    633\u001b[0m sorted_row_positions \u001b[39m=\u001b[39m (\n\u001b[1;32m    634\u001b[0m     row_positions\n\u001b[1;32m    635\u001b[0m     \u001b[39mif\u001b[39;00m (\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    641\u001b[0m     \u001b[39melse\u001b[39;00m np\u001b[39m.\u001b[39msort(row_positions)\n\u001b[1;32m    642\u001b[0m )\n\u001b[1;32m    643\u001b[0m \u001b[39m# Get dict of row_parts as {row_index: row_internal_indices}\u001b[39;00m\n\u001b[1;32m    644\u001b[0m \u001b[39m# TODO: Rename `row_partitions_list`->`row_partitions_dict`\u001b[39;00m\n\u001b[0;32m--> 645\u001b[0m row_partitions_list \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_dict_of_block_index(\n\u001b[1;32m    646\u001b[0m     \u001b[39m0\u001b[39;49m, sorted_row_positions, are_indices_sorted\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[1;32m    647\u001b[0m )\n\u001b[1;32m    648\u001b[0m new_row_lengths \u001b[39m=\u001b[39m [\n\u001b[1;32m    649\u001b[0m     \u001b[39mlen\u001b[39m(\n\u001b[1;32m    650\u001b[0m         \u001b[39m# Row lengths for slice are calculated as the length of the slice\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    657\u001b[0m     \u001b[39mfor\u001b[39;00m part_idx, part_indexer \u001b[39min\u001b[39;00m row_partitions_list\u001b[39m.\u001b[39mitems()\n\u001b[1;32m    658\u001b[0m ]\n\u001b[1;32m    659\u001b[0m new_index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex[\n\u001b[1;32m    660\u001b[0m     \u001b[39m# pandas Index is more likely to preserve its metadata if the indexer is slice\u001b[39;00m\n\u001b[1;32m    661\u001b[0m     \u001b[39mslice\u001b[39m(row_positions\u001b[39m.\u001b[39mstart, row_positions\u001b[39m.\u001b[39mstop, row_positions\u001b[39m.\u001b[39mstep)\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    664\u001b[0m     \u001b[39melse\u001b[39;00m sorted_row_positions\n\u001b[1;32m    665\u001b[0m ]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/modin/logging/logger_metaclass.py:68\u001b[0m, in \u001b[0;36mlogger_class_wrapper.<locals>.log_wrap\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     66\u001b[0m     logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEND::PANDAS-API::\u001b[39m\u001b[39m{\u001b[39;00mclass_name\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mmethod_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     67\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n\u001b[0;32m---> 68\u001b[0m \u001b[39mreturn\u001b[39;00m method(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.10/site-packages/modin/core/dataframe/pandas/dataframe/dataframe.py:1216\u001b[0m, in \u001b[0;36mPandasDataframe._get_dict_of_block_index\u001b[0;34m(self, axis, indices, are_indices_sorted)\u001b[0m\n\u001b[1;32m   1213\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(indices, \u001b[39mlist\u001b[39m):\n\u001b[1;32m   1214\u001b[0m     \u001b[39m# Converting python list to numpy for faster processing\u001b[39;00m\n\u001b[1;32m   1215\u001b[0m     indices \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(indices, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mint64)\n\u001b[0;32m-> 1216\u001b[0m negative_mask \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mless(indices, \u001b[39m0\u001b[39;49m)\n\u001b[1;32m   1217\u001b[0m has_negative \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39many(negative_mask)\n\u001b[1;32m   1218\u001b[0m \u001b[39mif\u001b[39;00m has_negative:\n\u001b[1;32m   1219\u001b[0m     \u001b[39m# We're going to modify 'indices' inplace in a numpy way, so doing a copy/converting indices to numpy.\u001b[39;00m\n",
      "\u001b[0;31mUFuncTypeError\u001b[0m: ufunc 'less' did not contain a loop with signature matching types (<class 'numpy.dtype[str_]'>, <class 'numpy.dtype[int64]'>) -> <class 'numpy.dtype[bool_]'>"
     ]
    }
   ],
   "source": [
    "# Let's build a set of tags, lowercase and remove duplicates with set, so we can save a label encoder\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import time\n",
    "start = time.time()\n",
    "# lowercase\n",
    "df_tags['tags'] = df_tags['tags'].apply(lambda x: [tag.lower() for tag in x])\n",
    "le = LabelEncoder()\n",
    "tags = set()\n",
    "for i in range(len(df_tags)):\n",
    "    tags.update(df_tags['tags'][i])\n",
    "tags = list(tags)\n",
    "le.fit(tags)\n",
    "# save classes of encoder\n",
    "import pickle\n",
    "with open('data/full/tags.pkl', 'wb') as f:\n",
    "    pickle.dump(le.classes_, f)\n",
    "# save also a csv with the tags so its easier to read\n",
    "df_tags.to_csv('data/full/tags.csv')\n",
    "stop = time.time()\n",
    "print('Time: ', stop - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build vocabulary\n",
    "import numpy as np\n",
    "import gensim\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "from gensim.downloader import api\n",
    "\n",
    "# build vocabulary\n",
    "glove = api.load(\"glove-wiki-gigaword-50\")\n",
    "print(glove.most_similar(\"cat\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove.build_vocab(df_tags, update=True)\n",
    "glove.train(df_tags, total_examples=glove.corpus_count, epochs=glove.epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ada",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ac29d0fc6b0188101944722695454f1e9e17731afb2c274abaf6b8203f21da01"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
